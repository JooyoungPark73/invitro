time="Jun 19 00:11:27.336" level=debug msg="Parsing function invocation trace data/gpttraces/example/invocations.csv (duration: 10 min)"
time="Jun 19 00:11:27.336" level=debug msg="Parsing function duration trace: data/gpttraces/example/durations.csv\n"
time="Jun 19 00:11:27.336" level=info msg="Parsing function memory trace: data/gpttraces/example/memory.csv"
time="Jun 19 00:11:27.336" level=debug msg="Parsing function invocation trace data/gpttraces/example/iterations.csv (duration: 50 min)"
time="Jun 19 00:11:27.337" level=debug msg="Parsing function invocation trace data/gpttraces/example/batch.csv (duration: 50 min)"
time="Jun 19 00:11:27.337" level=info msg="shadowFunctions function name is gpttrace-func-0-9411904232446839849"
time="Jun 19 00:11:27.337" level=info msg="shadowFunctions function name is gpttrace-func-0-9411904232446839849"
time="Jun 19 00:11:27.337" level=info msg="shadowFunctions function name is gpttrace-func-0-9411904232446839849"
time="Jun 19 00:11:27.337" level=info msg="shadowFunctions function name is gpttrace-func-0-9411904232446839849"
time="Jun 19 00:11:27.337" level=info msg="Traces contain the following 4 functions:\n"
	gpttrace-func-0-9411904232446839849-gpu-1
	gpttrace-func-0-9411904232446839849-gpu-2
	gpttrace-func-0-9411904232446839849-gpu-4
	gpttrace-func-0-9411904232446839849-gpu-8
time="Jun 19 00:11:27.337" level=info msg="Using workloads/container/trace_func_gpt.yaml as a service YAML specification file.\n"
1 gpttrace-func-0-9411904232446839849-gpu-1
time="Jun 19 00:11:28.752" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-9411904232446839849-gpu-1 1000m 1000m 1024Mi 1 1 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-9411904232446839849-gpu-1' in namespace 'default':\n\n  0.055s The Route is still working to reflect the latest desired specification.\n  0.096s ...\n  0.117s Configuration \"gpttrace-func-0-9411904232446839849-gpu-1\" is waiting for a Revision to become ready.\n  0.928s ...\n  0.969s Ingress has not yet been reconciled.\n  1.059s Waiting for load balancer to be ready\n  1.276s Ready to serve.\n\nService 'gpttrace-func-0-9411904232446839849-gpu-1' created to latest revision 'gpttrace-func-0-9411904232446839849-gpu-1-00001' is available at URL:\nhttp://gpttrace-func-0-9411904232446839849-gpu-1.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:28.752" level=debug msg="Update function endpoint to gpttrace-func-0-9411904232446839849-gpu-1.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:28.753" level=debug msg="Deployed function on gpttrace-func-0-9411904232446839849-gpu-1.default.10.200.3.4.sslip.io:80\n"
2 gpttrace-func-0-9411904232446839849-gpu-2
time="Jun 19 00:11:29.717" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-9411904232446839849-gpu-2 2000m 2000m 2048Mi 2 2 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-9411904232446839849-gpu-2' in namespace 'default':\n\n  0.024s The Route is still working to reflect the latest desired specification.\n  0.036s Configuration \"gpttrace-func-0-9411904232446839849-gpu-2\" is waiting for a Revision to become ready.\n  0.501s ...\n  0.546s Ingress has not yet been reconciled.\n  0.616s Waiting for load balancer to be ready\n  0.837s Ready to serve.\n\nService 'gpttrace-func-0-9411904232446839849-gpu-2' created to latest revision 'gpttrace-func-0-9411904232446839849-gpu-2-00001' is available at URL:\nhttp://gpttrace-func-0-9411904232446839849-gpu-2.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:29.718" level=debug msg="Update function endpoint to gpttrace-func-0-9411904232446839849-gpu-2.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:29.718" level=debug msg="Deployed function on gpttrace-func-0-9411904232446839849-gpu-2.default.10.200.3.4.sslip.io:80\n"
4 gpttrace-func-0-9411904232446839849-gpu-4
time="Jun 19 00:11:30.666" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-9411904232446839849-gpu-4 4000m 4000m 4096Mi 4 4 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-9411904232446839849-gpu-4' in namespace 'default':\n\n  0.038s The Route is still working to reflect the latest desired specification.\n  0.082s ...\n  0.132s Configuration \"gpttrace-func-0-9411904232446839849-gpu-4\" is waiting for a Revision to become ready.\n  0.515s ...\n  0.546s Ingress has not yet been reconciled.\n  0.629s Waiting for load balancer to be ready\n  0.850s Ready to serve.\n\nService 'gpttrace-func-0-9411904232446839849-gpu-4' created to latest revision 'gpttrace-func-0-9411904232446839849-gpu-4-00001' is available at URL:\nhttp://gpttrace-func-0-9411904232446839849-gpu-4.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:30.666" level=debug msg="Update function endpoint to gpttrace-func-0-9411904232446839849-gpu-4.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:30.667" level=debug msg="Deployed function on gpttrace-func-0-9411904232446839849-gpu-4.default.10.200.3.4.sslip.io:80\n"
8 gpttrace-func-0-9411904232446839849-gpu-8
time="Jun 19 00:11:31.712" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-9411904232446839849-gpu-8 8000m 8000m 8192Mi 8 8 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-9411904232446839849-gpu-8' in namespace 'default':\n\n  0.037s The Route is still working to reflect the latest desired specification.\n  0.085s ...\n  0.105s Configuration \"gpttrace-func-0-9411904232446839849-gpu-8\" is waiting for a Revision to become ready.\n  0.603s ...\n  0.640s Ingress has not yet been reconciled.\n  0.733s Waiting for load balancer to be ready\n  0.944s Ready to serve.\n\nService 'gpttrace-func-0-9411904232446839849-gpu-8' created to latest revision 'gpttrace-func-0-9411904232446839849-gpu-8-00001' is available at URL:\nhttp://gpttrace-func-0-9411904232446839849-gpu-8.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:31.712" level=debug msg="Update function endpoint to gpttrace-func-0-9411904232446839849-gpu-8.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:11:31.712" level=debug msg="Deployed function on gpttrace-func-0-9411904232446839849-gpu-8.default.10.200.3.4.sslip.io:80\n"
time="Jun 19 00:11:31.712" level=info msg="DepolyFunctions: Name[gpttrace-func-0-9411904232446839849-gpu-1], Port [gpttrace-func-0-9411904232446839849-gpu-1.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:11:31.712" level=info msg="DepolyFunctions: Name[gpttrace-func-0-9411904232446839849-gpu-2], Port [gpttrace-func-0-9411904232446839849-gpu-2.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:11:31.712" level=info msg="DepolyFunctions: Name[gpttrace-func-0-9411904232446839849-gpu-4], Port [gpttrace-func-0-9411904232446839849-gpu-4.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:11:31.712" level=info msg="DepolyFunctions: Name[gpttrace-func-0-9411904232446839849-gpu-8], Port [gpttrace-func-0-9411904232446839849-gpu-8.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:11:31.712" level=info msg="Generating IAT and runtime specifications for all the functions"
time="Jun 19 00:11:31.712" level=debug msg="Starting writer for data/out/experiment_duration_10_ClientTraining_single.csv"
time="Jun 19 00:11:31.712" level=info msg="Starting function invocation driver\n"
invoke function &{gpttrace-func-0-9411904232446839849-gpu-1 gpttrace-func-0-9411904232446839849-gpu-1.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dca20 0xc000136800 1000 1024 1000 0xc0000240a0}
invoke function &{gpttrace-func-0-9411904232446839849-gpu-2 gpttrace-func-0-9411904232446839849-gpu-2.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dca20 0xc000136800 1000 1024 1000 0xc0000240f0}
invoke function &{gpttrace-func-0-9411904232446839849-gpu-4 gpttrace-func-0-9411904232446839849-gpu-4.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dca20 0xc000136800 1000 1024 1000 0xc000024140}
invoke function &{gpttrace-func-0-9411904232446839849-gpu-8 gpttrace-func-0-9411904232446839849-gpu-8.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dca20 0xc000136800 1000 1024 1000 0xc000024190}
time="Jun 19 00:11:31.713" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:31.713" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 108[MiB]"
time="Jun 19 00:11:31.714" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:31.713" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:39.292" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:44.279" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:46.993" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 101[ms], 123[MiB]"
time="Jun 19 00:11:48.256" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 133[MiB]"
time="Jun 19 00:11:55.819" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:11:59.886" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:02.166" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:04.471" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:09.617" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 118[MiB]"
time="Jun 19 00:12:09.964" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:13.594" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:12:13.594" level=debug msg="**************** SingleInvoke invocationID min0.inv0, actual duration per iteration 98 [ms], response Time 6 [ms]"
time="Jun 19 00:12:13.594" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.75[ms], 123[MiB]"
time="Jun 19 00:12:13.594" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 41881.00[ms]\n"
time="Jun 19 00:12:13.594" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.64] \n"
time="Jun 19 00:12:22.237" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:22.267" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:26.075" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 119[MiB]"
time="Jun 19 00:12:26.257" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:28.098" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:31.394" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:31.713" level=debug msg="End of minute 0\n"
time="Jun 19 00:12:31.713" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 122[MiB]"
time="Jun 19 00:12:31.713" level=debug msg="Start of minute 1\n"
time="Jun 19 00:12:31.713" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:31.713" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:31.713" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:39.193" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:40.169" level=debug msg="print minReplicas 2, iterations 500 "
time="Jun 19 00:12:40.169" level=debug msg="**************** SingleInvoke invocationID min0.inv1, actual duration per iteration 98 [ms], response Time 5 [ms]"
time="Jun 19 00:12:40.170" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.22[ms], 123[MiB]"
time="Jun 19 00:12:40.170" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 51913.15[ms]\n"
time="Jun 19 00:12:40.170" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.46] \n"
time="Jun 19 00:12:44.674" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:48.740" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:50.159" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:52.182" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 127[MiB]"
time="Jun 19 00:12:52.587" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 101[ms], 123[MiB]"
time="Jun 19 00:12:55.220" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:12:57.044" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:13:07.217" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:08.265" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:10.104" level=debug msg="print minReplicas 8, iterations 800 "
time="Jun 19 00:13:10.104" level=debug msg="**************** SingleInvoke invocationID min0.inv2, actual duration per iteration 100 [ms], response Time 3 [ms]"
time="Jun 19 00:13:10.104" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 1009.59[ms], 123[MiB]"
time="Jun 19 00:13:10.104" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 83110.56[ms]\n"
time="Jun 19 00:13:10.104" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.32] \n"
time="Jun 19 00:13:14.205" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 151[MiB]"
time="Jun 19 00:13:15.871" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:16.283" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:16.988" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:13:16.988" level=debug msg="**************** SingleInvoke invocationID min1.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:13:16.988" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.78[ms], 123[MiB]"
time="Jun 19 00:13:16.988" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 19942.91[ms]\n"
time="Jun 19 00:13:16.988" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.82] \n"
time="Jun 19 00:13:18.011" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:27.543" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:28.979" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:29.299" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:13:29.299" level=debug msg="**************** SingleInvoke invocationID min0.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:13:29.299" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.14[ms], 123[MiB]"
time="Jun 19 00:13:29.299" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 79681.69[ms]\n"
time="Jun 19 00:13:29.299" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.09] \n"
time="Jun 19 00:13:31.713" level=debug msg="End of minute 1\n"
time="Jun 19 00:13:31.713" level=debug msg="Start of minute 2\n"
time="Jun 19 00:13:31.714" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:31.714" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:31.714" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:31.714" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 128[MiB]"
time="Jun 19 00:13:33.249" level=debug msg="print minReplicas 2, iterations 400 "
time="Jun 19 00:13:33.249" level=debug msg="**************** SingleInvoke invocationID min1.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:13:33.249" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 1009.05[ms], 123[MiB]"
time="Jun 19 00:13:33.249" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 40661.72[ms]\n"
time="Jun 19 00:13:33.249" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.66] \n"
time="Jun 19 00:13:36.570" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:41.150" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:44.690" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:13:44.690" level=debug msg="**************** SingleInvoke invocationID min1.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:13:44.690" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1009.44[ms], 123[MiB]"
time="Jun 19 00:13:44.690" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 30485.08[ms]\n"
time="Jun 19 00:13:44.690" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.96] \n"
time="Jun 19 00:13:46.562" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:13:46.562" level=debug msg="**************** SingleInvoke invocationID min0.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:13:46.562" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 999.22[ms], 123[MiB]"
time="Jun 19 00:13:46.562" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 80486.96[ms]\n"
time="Jun 19 00:13:46.562" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.07] \n"
time="Jun 19 00:13:48.738" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:13:53.797" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:01.369" level=debug msg="print minReplicas 2, iterations 900 "
time="Jun 19 00:14:01.369" level=debug msg="**************** SingleInvoke invocationID min1.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:14:01.369" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 990.21[ms], 123[MiB]"
time="Jun 19 00:14:01.369" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 89655.59[ms]\n"
time="Jun 19 00:14:01.369" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.31] \n"
time="Jun 19 00:14:01.904" level=debug msg="print minReplicas 2, iterations 700 "
time="Jun 19 00:14:01.904" level=debug msg="**************** SingleInvoke invocationID min1.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:14:01.904" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.47[ms], 123[MiB]"
time="Jun 19 00:14:01.904" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 69721.46[ms]\n"
time="Jun 19 00:14:01.904" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.17] \n"
time="Jun 19 00:14:06.546" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 126[MiB]"
time="Jun 19 00:14:08.400" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:09.362" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:13.004" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:14.323" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 122[MiB]"
time="Jun 19 00:14:16.100" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:17.332" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:17.547" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 114[MiB]"
time="Jun 19 00:14:25.357" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 123[MiB]"
time="Jun 19 00:14:27.324" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:27.339" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:28.419" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:31.712" level=debug msg="End of minute 2\n"
time="Jun 19 00:14:31.713" level=debug msg="Start of minute 3\n"
time="Jun 19 00:14:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:31.715" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 101[ms], 118[MiB]"
time="Jun 19 00:14:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:32.691" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:14:32.691" level=debug msg="**************** SingleInvoke invocationID min2.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:14:32.691" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1009.72[ms], 123[MiB]"
time="Jun 19 00:14:32.691" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 60976.80[ms]\n"
time="Jun 19 00:14:32.691" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.62] \n"
time="Jun 19 00:14:34.669" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:14:34.669" level=debug msg="**************** SingleInvoke invocationID min2.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:14:34.669" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1009.65[ms], 123[MiB]"
time="Jun 19 00:14:34.669" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 20345.69[ms]\n"
time="Jun 19 00:14:34.669" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.16] \n"
time="Jun 19 00:14:39.166" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:40.215" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:45.492" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 120[MiB]"
time="Jun 19 00:14:46.288" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:46.984" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:47.187" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 121[MiB]"
time="Jun 19 00:14:50.016" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:54.446" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:14:57.809" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:01.431" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:09.816" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:13.477" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:15.666" level=debug msg="print minReplicas 1, iterations 500 "
time="Jun 19 00:15:15.666" level=debug msg="**************** SingleInvoke invocationID min2.inv3, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:15:15.666" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1000.05[ms], 123[MiB]"
time="Jun 19 00:15:15.666" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 50307.95[ms]\n"
time="Jun 19 00:15:15.666" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.31] \n"
time="Jun 19 00:15:16.206" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 105[MiB]"
time="Jun 19 00:15:16.265" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:15:16.265" level=debug msg="**************** SingleInvoke invocationID min2.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:15:16.265" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.09[ms], 123[MiB]"
time="Jun 19 00:15:16.265" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 69719.35[ms]\n"
time="Jun 19 00:15:16.265" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.53] \n"
time="Jun 19 00:15:16.371" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:21.710" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-4: 99[ms], 124[MiB]"
time="Jun 19 00:15:26.672" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:31.713" level=debug msg="End of minute 3\n"
time="Jun 19 00:15:31.713" level=debug msg="Start of minute 4\n"
time="Jun 19 00:15:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:31.715" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:31.715" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 119[MiB]"
time="Jun 19 00:15:36.214" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:37.212" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:15:37.212" level=debug msg="**************** SingleInvoke invocationID min2.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:15:37.212" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 990.17[ms], 123[MiB]"
time="Jun 19 00:15:37.212" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 79664.80[ms]\n"
time="Jun 19 00:15:37.212" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.08] \n"
time="Jun 19 00:15:37.305" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-4: 100[ms], 111[MiB]"
time="Jun 19 00:15:42.930" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:43.983" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:44.286" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:15:44.769" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:45.726" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:46.580" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:48.000" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:15:52.987" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:15:52.987" level=debug msg="**************** SingleInvoke invocationID min3.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:15:52.987" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 1009.45[ms], 123[MiB]"
time="Jun 19 00:15:52.987" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 81272.01[ms]\n"
time="Jun 19 00:15:52.987" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-5.60] \n"
time="Jun 19 00:15:56.913" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:15:56.913" level=debug msg="**************** SingleInvoke invocationID min3.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:15:56.913" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.69[ms], 123[MiB]"
time="Jun 19 00:15:56.913" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 69725.86[ms]\n"
time="Jun 19 00:15:56.913" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.42] \n"
time="Jun 19 00:16:00.853" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 140[MiB]"
time="Jun 19 00:16:05.624" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:09.187" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:09.499" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:15.123" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:16:15.123" level=debug msg="**************** SingleInvoke invocationID min3.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:16:15.123" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 990.15[ms], 123[MiB]"
time="Jun 19 00:16:15.123" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 89630.60[ms]\n"
time="Jun 19 00:16:15.123" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.13] \n"
time="Jun 19 00:16:16.553" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:16:16.553" level=debug msg="**************** SingleInvoke invocationID min3.inv3, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:16:16.553" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1000.20[ms], 123[MiB]"
time="Jun 19 00:16:16.553" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 60346.52[ms]\n"
time="Jun 19 00:16:16.553" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.58] \n"
time="Jun 19 00:16:19.139" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 119[MiB]"
time="Jun 19 00:16:20.793" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:22.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:24.123" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:16:24.123" level=debug msg="**************** SingleInvoke invocationID min4.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:16:24.123" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 990.13[ms], 123[MiB]"
time="Jun 19 00:16:24.123" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 39836.85[ms]\n"
time="Jun 19 00:16:24.123" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.06] \n"
time="Jun 19 00:16:27.615" level=debug msg="print minReplicas 4, iterations 500 "
time="Jun 19 00:16:27.615" level=debug msg="**************** SingleInvoke invocationID min4.inv1, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:16:27.615" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-4: this is reply, 999.87[ms], 123[MiB]"
time="Jun 19 00:16:27.615" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-4: 50309.52[ms]\n"
time="Jun 19 00:16:27.615" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.35] \n"
time="Jun 19 00:16:31.713" level=debug msg="End of minute 4\n"
time="Jun 19 00:16:31.713" level=debug msg="Start of minute 5\n"
time="Jun 19 00:16:31.716" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 112[MiB]"
time="Jun 19 00:16:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:32.485" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:32.659" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:16:32.659" level=debug msg="**************** SingleInvoke invocationID min4.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:16:32.659" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1009.30[ms], 123[MiB]"
time="Jun 19 00:16:32.659" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 60943.78[ms]\n"
time="Jun 19 00:16:32.659" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.40] \n"
time="Jun 19 00:16:33.740" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:37.643" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:43.170" level=debug msg="print minReplicas 4, iterations 800 "
time="Jun 19 00:16:43.170" level=debug msg="**************** SingleInvoke invocationID min3.inv4, actual duration per iteration 98 [ms], response Time 3 [ms]"
time="Jun 19 00:16:43.170" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-4: this is reply, 989.09[ms], 123[MiB]"
time="Jun 19 00:16:43.170" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-4: 81459.87[ms]\n"
time="Jun 19 00:16:43.170" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.38] \n"
time="Jun 19 00:16:51.262" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 99[ms], 118[MiB]"
time="Jun 19 00:16:52.915" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:53.374" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 101[ms], 103[MiB]"
time="Jun 19 00:16:55.235" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:58.594" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:16:59.365" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:16:59.365" level=debug msg="**************** SingleInvoke invocationID min4.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:16:59.365" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1000.02[ms], 123[MiB]"
time="Jun 19 00:16:59.365" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 40225.84[ms]\n"
time="Jun 19 00:16:59.365" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.34] \n"
time="Jun 19 00:17:00.305" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:01.371" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:03.588" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 99[ms], 117[MiB]"
time="Jun 19 00:17:05.963" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:11.760" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:13.321" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:24.543" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 99[ms], 122[MiB]"
time="Jun 19 00:17:28.293" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:31.493" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:17:31.493" level=debug msg="**************** SingleInvoke invocationID min5.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:17:31.493" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 990.18[ms], 123[MiB]"
time="Jun 19 00:17:31.493" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 59776.86[ms]\n"
time="Jun 19 00:17:31.493" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.76] \n"
time="Jun 19 00:17:31.713" level=debug msg="End of minute 5\n"
time="Jun 19 00:17:31.713" level=debug msg="Start of minute 6\n"
time="Jun 19 00:17:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:31.716" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 115[MiB]"
time="Jun 19 00:17:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:32.278" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:17:32.279" level=debug msg="**************** SingleInvoke invocationID min4.inv3, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:17:32.279" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1010.12[ms], 123[MiB]"
time="Jun 19 00:17:32.279" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 91424.79[ms]\n"
time="Jun 19 00:17:32.279" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.48] \n"
time="Jun 19 00:17:33.393" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 126[MiB]"
time="Jun 19 00:17:36.614" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:42.958" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:51.220" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:17:58.650" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:01.910" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:18:01.911" level=debug msg="**************** SingleInvoke invocationID min6.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:18:01.911" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 999.73[ms], 123[MiB]"
time="Jun 19 00:18:01.911" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 30194.55[ms]\n"
time="Jun 19 00:18:01.911" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.11] \n"
time="Jun 19 00:18:05.197" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:18:05.692" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-4: 100[ms], 126[MiB]"
time="Jun 19 00:18:12.673" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:13.558" level=debug msg="print minReplicas 8, iterations 200 "
time="Jun 19 00:18:13.559" level=debug msg="**************** SingleInvoke invocationID min5.inv1, actual duration per iteration 98 [ms], response Time 313 [ms]"
time="Jun 19 00:18:13.559" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 989.25[ms], 123[MiB]"
time="Jun 19 00:18:13.559" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 82296.18[ms]\n"
time="Jun 19 00:18:13.559" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.32] \n"
time="Jun 19 00:18:13.651" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:18.194" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:20.687" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 108[MiB]"
time="Jun 19 00:18:21.312" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:22.941" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:23.201" level=debug msg="print minReplicas 1, iterations 500 "
time="Jun 19 00:18:23.201" level=debug msg="**************** SingleInvoke invocationID min6.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:18:23.201" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.84[ms], 123[MiB]"
time="Jun 19 00:18:23.201" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 49807.35[ms]\n"
time="Jun 19 00:18:23.201" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.56] \n"
time="Jun 19 00:18:25.170" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:26.316" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:30.394" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:31.713" level=debug msg="End of minute 6\n"
time="Jun 19 00:18:31.713" level=debug msg="Start of minute 7\n"
time="Jun 19 00:18:31.716" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:31.717" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 105[MiB]"
time="Jun 19 00:18:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:35.561" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:43.169" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:43.298" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:43.713" level=debug msg="print minReplicas 2, iterations 100 "
time="Jun 19 00:18:43.713" level=debug msg="**************** SingleInvoke invocationID min7.inv0, actual duration per iteration 98 [ms], response Time 21 [ms]"
time="Jun 19 00:18:43.713" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.52[ms], 123[MiB]"
time="Jun 19 00:18:43.713" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 11996.26[ms]\n"
time="Jun 19 00:18:43.713" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.88] \n"
time="Jun 19 00:18:43.718" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:47.232" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:18:48.011" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 100[ms], 131[MiB]"
time="Jun 19 00:18:48.504" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:18:53.638" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 113[MiB]"
time="Jun 19 00:18:53.835" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:00.461" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:06.787" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:07.814" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:07.824" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:19:07.824" level=debug msg="**************** SingleInvoke invocationID min6.inv2, actual duration per iteration 99 [ms], response Time 4 [ms]"
time="Jun 19 00:19:07.824" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-4: this is reply, 1000.14[ms], 123[MiB]"
time="Jun 19 00:19:07.824" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-4: 62131.75[ms]\n"
time="Jun 19 00:19:07.824" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.86] \n"
time="Jun 19 00:19:12.624" level=debug msg="print minReplicas 8, iterations 300 "
time="Jun 19 00:19:12.624" level=debug msg="**************** SingleInvoke invocationID min5.inv4, actual duration per iteration 98 [ms], response Time 262 [ms]"
time="Jun 19 00:19:12.624" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 989.71[ms], 123[MiB]"
time="Jun 19 00:19:12.624" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 108080.59[ms]\n"
time="Jun 19 00:19:12.624" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.21] \n"
time="Jun 19 00:19:16.405" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:22.654" level=debug msg="print minReplicas 8, iterations 400 "
time="Jun 19 00:19:22.654" level=debug msg="**************** SingleInvoke invocationID min5.inv3, actual duration per iteration 98 [ms], response Time 249 [ms]"
time="Jun 19 00:19:22.654" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 989.59[ms], 123[MiB]"
time="Jun 19 00:19:22.654" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 139065.74[ms]\n"
time="Jun 19 00:19:22.654" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.32] \n"
time="Jun 19 00:19:23.714" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:24.853" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:19:24.853" level=debug msg="**************** SingleInvoke invocationID min6.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:19:24.853" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.40[ms], 123[MiB]"
time="Jun 19 00:19:24.853" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 79655.83[ms]\n"
time="Jun 19 00:19:24.853" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-7.85] \n"
time="Jun 19 00:19:27.069" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:19:27.069" level=debug msg="**************** SingleInvoke invocationID min7.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:19:27.069" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.34[ms], 123[MiB]"
time="Jun 19 00:19:27.069" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 39836.78[ms]\n"
time="Jun 19 00:19:27.069" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.90] \n"
time="Jun 19 00:19:27.812" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:31.651" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-4: 99[ms], 122[MiB]"
time="Jun 19 00:19:31.713" level=debug msg="End of minute 7\n"
time="Jun 19 00:19:31.713" level=debug msg="Start of minute 8\n"
time="Jun 19 00:19:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:31.717" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 100[ms], 114[MiB]"
time="Jun 19 00:19:37.346" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:38.782" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 101[ms], 114[MiB]"
time="Jun 19 00:19:40.364" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:19:40.364" level=debug msg="**************** SingleInvoke invocationID min6.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:19:40.364" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.23[ms], 123[MiB]"
time="Jun 19 00:19:40.364" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 79676.49[ms]\n"
time="Jun 19 00:19:40.364" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.46] \n"
time="Jun 19 00:19:41.831" level=debug msg="print minReplicas 8, iterations 500 "
time="Jun 19 00:19:41.831" level=debug msg="**************** SingleInvoke invocationID min5.inv2, actual duration per iteration 100 [ms], response Time 236 [ms]"
time="Jun 19 00:19:41.831" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 1010.02[ms], 123[MiB]"
time="Jun 19 00:19:41.831" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 168456.89[ms]\n"
time="Jun 19 00:19:41.831" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-5.75] \n"
time="Jun 19 00:19:43.462" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 122[MiB]"
time="Jun 19 00:19:43.916" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:52.762" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:58.448" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:19:58.951" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:04.732" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 129[MiB]"
time="Jun 19 00:20:09.261" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:20:09.261" level=debug msg="**************** SingleInvoke invocationID min8.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:20:09.261" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 1009.09[ms], 123[MiB]"
time="Jun 19 00:20:09.261" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 30478.46[ms]\n"
time="Jun 19 00:20:09.261" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.69] \n"
time="Jun 19 00:20:13.312" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:20:13.312" level=debug msg="**************** SingleInvoke invocationID min7.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:20:13.312" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.88[ms], 123[MiB]"
time="Jun 19 00:20:13.312" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 79673.72[ms]\n"
time="Jun 19 00:20:13.312" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.21] \n"
time="Jun 19 00:20:17.268" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:20.034" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:22.587" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:24.074" level=debug msg="print minReplicas 8, iterations 600 "
time="Jun 19 00:20:24.074" level=debug msg="**************** SingleInvoke invocationID min7.inv2, actual duration per iteration 99 [ms], response Time 61 [ms]"
time="Jun 19 00:20:24.074" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 999.76[ms], 123[MiB]"
time="Jun 19 00:20:24.074" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 96063.10[ms]\n"
time="Jun 19 00:20:24.074" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.76] \n"
time="Jun 19 00:20:28.628" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:28.702" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 101[ms], 133[MiB]"
time="Jun 19 00:20:29.411" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:30.427" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:30.748" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:31.412" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:20:31.412" level=debug msg="**************** SingleInvoke invocationID min7.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:20:31.412" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-4: this is reply, 989.53[ms], 123[MiB]"
time="Jun 19 00:20:31.412" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-4: 59760.17[ms]\n"
time="Jun 19 00:20:31.412" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.87] \n"
time="Jun 19 00:20:31.713" level=debug msg="End of minute 8\n"
time="Jun 19 00:20:31.713" level=debug msg="Start of minute 9\n"
time="Jun 19 00:20:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:31.717" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-1: 99[ms], 130[MiB]"
time="Jun 19 00:20:31.717" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:32.063" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:20:32.063" level=debug msg="**************** SingleInvoke invocationID min8.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:20:32.063" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 999.55[ms], 123[MiB]"
time="Jun 19 00:20:32.063" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 60345.84[ms]\n"
time="Jun 19 00:20:32.063" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.59] \n"
time="Jun 19 00:20:34.630" level=debug msg="print minReplicas 2, iterations 300 "
time="Jun 19 00:20:34.630" level=debug msg="**************** SingleInvoke invocationID min8.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:20:34.630" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.50[ms], 123[MiB]"
time="Jun 19 00:20:34.630" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 29897.17[ms]\n"
time="Jun 19 00:20:34.630" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.11] \n"
time="Jun 19 00:20:37.817" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:37.897" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:45.391" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-4: 101[ms], 125[MiB]"
time="Jun 19 00:20:51.681" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:55.360" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 99[ms], 120[MiB]"
time="Jun 19 00:20:57.688" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:20:59.208" level=debug msg="print minReplicas 2, iterations 300 "
time="Jun 19 00:20:59.208" level=debug msg="**************** SingleInvoke invocationID min8.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:20:59.208" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 1010.07[ms], 123[MiB]"
time="Jun 19 00:20:59.208" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 30505.72[ms]\n"
time="Jun 19 00:20:59.208" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.98] \n"
time="Jun 19 00:21:00.912" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-8: 101[ms], 134[MiB]"
time="Jun 19 00:21:03.137" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:21:03.137" level=debug msg="**************** SingleInvoke invocationID min8.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:21:03.137" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.09[ms], 123[MiB]"
time="Jun 19 00:21:03.137" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 79675.04[ms]\n"
time="Jun 19 00:21:03.137" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.36] \n"
time="Jun 19 00:21:03.318" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:06.698" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:07.590" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:09.388" level=debug msg="print minReplicas 8, iterations 100 "
time="Jun 19 00:21:09.388" level=debug msg="**************** SingleInvoke invocationID min9.inv2, actual duration per iteration 98 [ms], response Time 42 [ms]"
time="Jun 19 00:21:09.388" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 989.65[ms], 123[MiB]"
time="Jun 19 00:21:09.388" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 14027.75[ms]\n"
time="Jun 19 00:21:09.388" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.99] \n"
time="Jun 19 00:21:13.849" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:15.490" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:25.945" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:26.213" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:28.429" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:21:28.646" level=trace msg="(Invoke)\t gpttrace-func-0-9411904232446839849-gpu-2: 99[ms], 103[MiB]"
time="Jun 19 00:21:31.713" level=debug msg="End of minute 9\n"
time="Jun 19 00:21:35.797" level=debug msg="print minReplicas 8, iterations 300 "
time="Jun 19 00:21:35.797" level=debug msg="**************** SingleInvoke invocationID min9.inv3, actual duration per iteration 100 [ms], response Time 16 [ms]"
time="Jun 19 00:21:35.797" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-8: this is reply, 1009.13[ms], 123[MiB]"
time="Jun 19 00:21:35.797" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-8: 34884.28[ms]\n"
time="Jun 19 00:21:35.797" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.79] \n"
time="Jun 19 00:21:35.797" level=debug msg="All the invocations for function gpttrace-func-0-9411904232446839849-gpu-8 have been completed.\n"
time="Jun 19 00:21:36.413" level=debug msg="print minReplicas 4, iterations 500 "
time="Jun 19 00:21:36.413" level=debug msg="**************** SingleInvoke invocationID min9.inv1, actual duration per iteration 100 [ms], response Time 2 [ms]"
time="Jun 19 00:21:36.413" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-4: this is reply, 1009.16[ms], 123[MiB]"
time="Jun 19 00:21:36.413" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-4: 51022.57[ms]\n"
time="Jun 19 00:21:36.413" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.10] \n"
time="Jun 19 00:21:36.414" level=debug msg="All the invocations for function gpttrace-func-0-9411904232446839849-gpu-4 have been completed.\n"
time="Jun 19 00:22:01.356" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:22:01.356" level=debug msg="**************** SingleInvoke invocationID min9.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:22:01.356" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-1: this is reply, 989.79[ms], 123[MiB]"
time="Jun 19 00:22:01.356" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-1: 89638.39[ms]\n"
time="Jun 19 00:22:01.356" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.14] \n"
time="Jun 19 00:22:01.356" level=debug msg="All the invocations for function gpttrace-func-0-9411904232446839849-gpu-1 have been completed.\n"
time="Jun 19 00:22:48.327" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:22:48.327" level=debug msg="**************** SingleInvoke invocationID min9.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:22:48.327" level=trace msg="(Replied)\t gpttrace-func-0-9411904232446839849-gpu-2: this is reply, 989.45[ms], 123[MiB]"
time="Jun 19 00:22:48.327" level=trace msg="(E2E Latency) gpttrace-func-0-9411904232446839849-gpu-2: 79681.14[ms]\n"
time="Jun 19 00:22:48.328" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.75] \n"
time="Jun 19 00:22:48.328" level=debug msg="All the invocations for function gpttrace-func-0-9411904232446839849-gpu-2 have been completed.\n"
time="Jun 19 00:22:48.328" level=debug msg="Waiting for all the invocations record to be written.\n"
time="Jun 19 00:22:48.328" level=info msg="Trace has finished executing function invocation driver\n"
time="Jun 19 00:22:48.328" level=info msg="Number of successful invocations: \t200\n"
time="Jun 19 00:22:48.328" level=info msg="Number of failed invocations: \t0\n"
