time="Jun 19 00:23:49.292" level=debug msg="Parsing function invocation trace data/gpttraces/example/invocations.csv (duration: 20 min)"
time="Jun 19 00:23:49.293" level=debug msg="Parsing function duration trace: data/gpttraces/example/durations.csv\n"
time="Jun 19 00:23:49.293" level=info msg="Parsing function memory trace: data/gpttraces/example/memory.csv"
time="Jun 19 00:23:49.293" level=debug msg="Parsing function invocation trace data/gpttraces/example/iterations.csv (duration: 100 min)"
time="Jun 19 00:23:49.295" level=debug msg="Parsing function invocation trace data/gpttraces/example/batch.csv (duration: 100 min)"
time="Jun 19 00:23:49.296" level=info msg="shadowFunctions function name is gpttrace-func-0-8919973466490155915"
time="Jun 19 00:23:49.296" level=info msg="shadowFunctions function name is gpttrace-func-0-8919973466490155915"
time="Jun 19 00:23:49.296" level=info msg="shadowFunctions function name is gpttrace-func-0-8919973466490155915"
time="Jun 19 00:23:49.296" level=info msg="shadowFunctions function name is gpttrace-func-0-8919973466490155915"
time="Jun 19 00:23:49.296" level=info msg="Traces contain the following 4 functions:\n"
	gpttrace-func-0-8919973466490155915-gpu-1
	gpttrace-func-0-8919973466490155915-gpu-2
	gpttrace-func-0-8919973466490155915-gpu-4
	gpttrace-func-0-8919973466490155915-gpu-8
time="Jun 19 00:23:49.296" level=info msg="Using workloads/container/trace_func_gpt.yaml as a service YAML specification file.\n"
1 gpttrace-func-0-8919973466490155915-gpu-1
time="Jun 19 00:23:50.578" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-8919973466490155915-gpu-1 1000m 1000m 1024Mi 1 1 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-8919973466490155915-gpu-1' in namespace 'default':\n\n  0.042s The Route is still working to reflect the latest desired specification.\n  0.053s ...\n  0.088s Configuration \"gpttrace-func-0-8919973466490155915-gpu-1\" is waiting for a Revision to become ready.\n  0.764s ...\n  0.788s Ingress has not yet been reconciled.\n  0.883s Waiting for load balancer to be ready\n  1.105s Ready to serve.\n\nService 'gpttrace-func-0-8919973466490155915-gpu-1' created to latest revision 'gpttrace-func-0-8919973466490155915-gpu-1-00001' is available at URL:\nhttp://gpttrace-func-0-8919973466490155915-gpu-1.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:50.579" level=debug msg="Update function endpoint to gpttrace-func-0-8919973466490155915-gpu-1.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:50.579" level=debug msg="Deployed function on gpttrace-func-0-8919973466490155915-gpu-1.default.10.200.3.4.sslip.io:80\n"
2 gpttrace-func-0-8919973466490155915-gpu-2
time="Jun 19 00:23:51.553" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-8919973466490155915-gpu-2 2000m 2000m 2048Mi 2 2 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-8919973466490155915-gpu-2' in namespace 'default':\n\n  0.047s The Route is still working to reflect the latest desired specification.\n  0.085s Configuration \"gpttrace-func-0-8919973466490155915-gpu-2\" is waiting for a Revision to become ready.\n  0.132s ...\n  0.531s ...\n  0.579s Ingress has not yet been reconciled.\n  0.662s Waiting for load balancer to be ready\n  0.868s Ready to serve.\n\nService 'gpttrace-func-0-8919973466490155915-gpu-2' created to latest revision 'gpttrace-func-0-8919973466490155915-gpu-2-00001' is available at URL:\nhttp://gpttrace-func-0-8919973466490155915-gpu-2.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:51.553" level=debug msg="Update function endpoint to gpttrace-func-0-8919973466490155915-gpu-2.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:51.553" level=debug msg="Deployed function on gpttrace-func-0-8919973466490155915-gpu-2.default.10.200.3.4.sslip.io:80\n"
4 gpttrace-func-0-8919973466490155915-gpu-4
time="Jun 19 00:23:52.513" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-8919973466490155915-gpu-4 4000m 4000m 4096Mi 4 4 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-8919973466490155915-gpu-4' in namespace 'default':\n\n  0.049s The Route is still working to reflect the latest desired specification.\n  0.062s Configuration \"gpttrace-func-0-8919973466490155915-gpu-4\" is waiting for a Revision to become ready.\n  0.110s ...\n  0.514s ...\n  0.552s Ingress has not yet been reconciled.\n  0.623s Waiting for load balancer to be ready\n  0.850s Ready to serve.\n\nService 'gpttrace-func-0-8919973466490155915-gpu-4' created to latest revision 'gpttrace-func-0-8919973466490155915-gpu-4-00001' is available at URL:\nhttp://gpttrace-func-0-8919973466490155915-gpu-4.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:52.514" level=debug msg="Update function endpoint to gpttrace-func-0-8919973466490155915-gpu-4.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:52.514" level=debug msg="Deployed function on gpttrace-func-0-8919973466490155915-gpu-4.default.10.200.3.4.sslip.io:80\n"
8 gpttrace-func-0-8919973466490155915-gpu-8
time="Jun 19 00:23:53.501" level=debug msg="CMD response: workloads/container/trace_func_gpt.yaml gpttrace-func-0-8919973466490155915-gpu-8 8000m 8000m 8192Mi 8 8 0 \"10.0\" \"200.0\" \"concurrency\" \"100\"\nCreating service 'gpttrace-func-0-8919973466490155915-gpu-8' in namespace 'default':\n\n  0.041s The Route is still working to reflect the latest desired specification.\n  0.095s Configuration \"gpttrace-func-0-8919973466490155915-gpu-8\" is waiting for a Revision to become ready.\n  0.547s ...\n  0.576s Ingress has not yet been reconciled.\n  0.667s Waiting for load balancer to be ready\n  0.887s Ready to serve.\n\nService 'gpttrace-func-0-8919973466490155915-gpu-8' created to latest revision 'gpttrace-func-0-8919973466490155915-gpu-8-00001' is available at URL:\nhttp://gpttrace-func-0-8919973466490155915-gpu-8.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:53.502" level=debug msg="Update function endpoint to gpttrace-func-0-8919973466490155915-gpu-8.default.10.200.3.4.sslip.io\n"
time="Jun 19 00:23:53.502" level=debug msg="Deployed function on gpttrace-func-0-8919973466490155915-gpu-8.default.10.200.3.4.sslip.io:80\n"
time="Jun 19 00:23:53.502" level=info msg="DepolyFunctions: Name[gpttrace-func-0-8919973466490155915-gpu-1], Port [gpttrace-func-0-8919973466490155915-gpu-1.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:23:53.502" level=info msg="DepolyFunctions: Name[gpttrace-func-0-8919973466490155915-gpu-2], Port [gpttrace-func-0-8919973466490155915-gpu-2.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:23:53.502" level=info msg="DepolyFunctions: Name[gpttrace-func-0-8919973466490155915-gpu-4], Port [gpttrace-func-0-8919973466490155915-gpu-4.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:23:53.502" level=info msg="DepolyFunctions: Name[gpttrace-func-0-8919973466490155915-gpu-8], Port [gpttrace-func-0-8919973466490155915-gpu-8.default.10.200.3.4.sslip.io:80]"
time="Jun 19 00:23:53.502" level=info msg="Generating IAT and runtime specifications for all the functions"
time="Jun 19 00:23:53.502" level=debug msg="Starting writer for data/out/experiment_duration_20_ClientTraining_single.csv"
time="Jun 19 00:23:53.502" level=info msg="Starting function invocation driver\n"
invoke function &{gpttrace-func-0-8919973466490155915-gpu-1 gpttrace-func-0-8919973466490155915-gpu-1.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dcb40 0xc000136800 1000 1024 1000 0xc00012c230}
invoke function &{gpttrace-func-0-8919973466490155915-gpu-2 gpttrace-func-0-8919973466490155915-gpu-2.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dcb40 0xc000136800 1000 1024 1000 0xc00012c280}
invoke function &{gpttrace-func-0-8919973466490155915-gpu-4 gpttrace-func-0-8919973466490155915-gpu-4.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dcb40 0xc000136800 1000 1024 1000 0xc00012c2d0}
invoke function &{gpttrace-func-0-8919973466490155915-gpu-8 gpttrace-func-0-8919973466490155915-gpu-8.default.10.200.3.4.sslip.io:80 0 0xc00012ac00 0xc00012ad20 0xc00012ae40 0xc0001dcb40 0xc000136800 1000 1024 1000 0xc00012c320}
time="Jun 19 00:23:53.502" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:23:53.502" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:23:53.502" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 108[MiB]"
time="Jun 19 00:23:53.502" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:03.435" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:06.068" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 126[MiB]"
time="Jun 19 00:24:06.414" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:17.274" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:17.608" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:19.276" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:23.956" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:27.131" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 99[ms], 124[MiB]"
time="Jun 19 00:24:30.433" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:31.407" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 118[MiB]"
time="Jun 19 00:24:31.753" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:32.840" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:35.304" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:24:35.304" level=debug msg="**************** SingleInvoke invocationID min0.inv0, actual duration per iteration 98 [ms], response Time 6 [ms]"
time="Jun 19 00:24:35.304" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.56[ms], 123[MiB]"
time="Jun 19 00:24:35.304" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 41800.64[ms]\n"
time="Jun 19 00:24:35.304" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.13] \n"
time="Jun 19 00:24:44.027" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:47.864" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 119[MiB]"
time="Jun 19 00:24:48.048" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:49.749" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:53.502" level=debug msg="End of minute 0\n"
time="Jun 19 00:24:53.502" level=debug msg="Start of minute 1\n"
time="Jun 19 00:24:53.503" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:53.503" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 150[MiB]"
time="Jun 19 00:24:53.503" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:53.503" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:24:59.015" level=debug msg="print minReplicas 2, iterations 500 "
time="Jun 19 00:24:59.015" level=debug msg="**************** SingleInvoke invocationID min0.inv1, actual duration per iteration 100 [ms], response Time 5 [ms]"
time="Jun 19 00:24:59.015" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.91[ms], 123[MiB]"
time="Jun 19 00:24:59.015" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 52946.50[ms]\n"
time="Jun 19 00:24:59.015" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.71] \n"
time="Jun 19 00:25:06.464" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:07.417" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:09.502" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:10.531" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 100[MiB]"
time="Jun 19 00:25:17.009" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:18.834" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:25:25.569" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:35.994" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 151[MiB]"
time="Jun 19 00:25:36.670" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:37.661" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 132[MiB]"
time="Jun 19 00:25:38.793" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:25:38.793" level=debug msg="**************** SingleInvoke invocationID min1.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:25:38.793" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.08[ms], 123[MiB]"
time="Jun 19 00:25:38.793" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 19958.35[ms]\n"
time="Jun 19 00:25:38.793" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.82] \n"
time="Jun 19 00:25:42.330" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:43.772" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:44.191" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:45.991" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:48.612" level=debug msg="print minReplicas 8, iterations 800 "
time="Jun 19 00:25:48.612" level=debug msg="**************** SingleInvoke invocationID min0.inv2, actual duration per iteration 98 [ms], response Time 3 [ms]"
time="Jun 19 00:25:48.612" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 990.01[ms], 123[MiB]"
time="Jun 19 00:25:48.612" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 81480.50[ms]\n"
time="Jun 19 00:25:48.612" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.38] \n"
time="Jun 19 00:25:49.334" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:50.770" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:51.097" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:25:51.097" level=debug msg="**************** SingleInvoke invocationID min0.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:25:51.097" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.84[ms], 123[MiB]"
time="Jun 19 00:25:51.097" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 79690.50[ms]\n"
time="Jun 19 00:25:51.098" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.49] \n"
time="Jun 19 00:25:53.502" level=debug msg="End of minute 1\n"
time="Jun 19 00:25:53.502" level=debug msg="Start of minute 2\n"
time="Jun 19 00:25:53.504" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 128[MiB]"
time="Jun 19 00:25:53.504" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:53.504" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:53.504" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:25:58.361" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:06.486" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:26:06.486" level=debug msg="**************** SingleInvoke invocationID min1.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:26:06.486" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1009.70[ms], 123[MiB]"
time="Jun 19 00:26:06.486" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 30492.06[ms]\n"
time="Jun 19 00:26:06.486" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.38] \n"
time="Jun 19 00:26:08.342" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:26:08.342" level=debug msg="**************** SingleInvoke invocationID min0.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:26:08.342" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.13[ms], 123[MiB]"
time="Jun 19 00:26:08.342" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 80477.30[ms]\n"
time="Jun 19 00:26:08.342" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.41] \n"
time="Jun 19 00:26:15.733" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:17.369" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:17.508" level=debug msg="print minReplicas 2, iterations 400 "
time="Jun 19 00:26:17.509" level=debug msg="**************** SingleInvoke invocationID min1.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:26:17.509" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.54[ms], 123[MiB]"
time="Jun 19 00:26:17.509" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 39847.15[ms]\n"
time="Jun 19 00:26:17.509" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.52] \n"
time="Jun 19 00:26:20.247" level=debug msg="print minReplicas 2, iterations 700 "
time="Jun 19 00:26:20.247" level=debug msg="**************** SingleInvoke invocationID min1.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:26:20.247" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.86[ms], 123[MiB]"
time="Jun 19 00:26:20.247" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 69715.65[ms]\n"
time="Jun 19 00:26:20.247" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.02] \n"
time="Jun 19 00:26:21.036" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:23.133" level=debug msg="print minReplicas 2, iterations 900 "
time="Jun 19 00:26:23.133" level=debug msg="**************** SingleInvoke invocationID min1.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:26:23.133" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.82[ms], 123[MiB]"
time="Jun 19 00:26:23.133" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 89629.53[ms]\n"
time="Jun 19 00:26:23.133" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.33] \n"
time="Jun 19 00:26:28.336" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 126[MiB]"
time="Jun 19 00:26:28.703" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:30.101" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:36.114" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 122[MiB]"
time="Jun 19 00:26:37.891" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:46.769" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:47.148" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 123[MiB]"
time="Jun 19 00:26:49.114" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:49.130" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 100[ms], 114[MiB]"
time="Jun 19 00:26:49.307" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:50.209" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:51.968" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:53.503" level=debug msg="End of minute 2\n"
time="Jun 19 00:26:53.503" level=debug msg="Start of minute 3\n"
time="Jun 19 00:26:53.505" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 118[MiB]"
time="Jun 19 00:26:53.505" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:53.505" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:53.505" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:26:54.466" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:26:54.466" level=debug msg="**************** SingleInvoke invocationID min2.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:26:54.466" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1009.26[ms], 123[MiB]"
time="Jun 19 00:26:54.466" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 60961.15[ms]\n"
time="Jun 19 00:26:54.466" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-5.06] \n"
time="Jun 19 00:26:56.443" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:26:56.444" level=debug msg="**************** SingleInvoke invocationID min2.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:26:56.444" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1010.04[ms], 123[MiB]"
time="Jun 19 00:26:56.444" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 20329.66[ms]\n"
time="Jun 19 00:26:56.444" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.85] \n"
time="Jun 19 00:26:56.975" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:00.625" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:04.111" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:07.283" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 120[MiB]"
time="Jun 19 00:27:08.978" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 121[MiB]"
time="Jun 19 00:27:11.806" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:16.236" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:19.599" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:25.791" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:36.138" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:37.459" level=debug msg="print minReplicas 1, iterations 500 "
time="Jun 19 00:27:37.459" level=debug msg="**************** SingleInvoke invocationID min2.inv3, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:27:37.459" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1000.19[ms], 123[MiB]"
time="Jun 19 00:27:37.459" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 50311.14[ms]\n"
time="Jun 19 00:27:37.459" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.51] \n"
time="Jun 19 00:27:37.744" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:37.997" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 105[MiB]"
time="Jun 19 00:27:38.080" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:27:38.080" level=debug msg="**************** SingleInvoke invocationID min2.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:27:38.080" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.06[ms], 123[MiB]"
time="Jun 19 00:27:38.080" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 69743.63[ms]\n"
time="Jun 19 00:27:38.080" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.54] \n"
time="Jun 19 00:27:43.500" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:44.333" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:48.462" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:50.530" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 101[ms], 103[MiB]"
time="Jun 19 00:27:53.502" level=debug msg="End of minute 3\n"
time="Jun 19 00:27:53.503" level=debug msg="Start of minute 4\n"
time="Jun 19 00:27:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:53.506" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 119[MiB]"
time="Jun 19 00:27:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:58.004" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:27:59.095" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:05.774" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:06.076" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:28:08.371" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:09.621" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:28:09.621" level=debug msg="**************** SingleInvoke invocationID min2.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:28:09.621" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 999.84[ms], 123[MiB]"
time="Jun 19 00:28:09.621" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 80490.98[ms]\n"
time="Jun 19 00:28:09.621" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.50] \n"
time="Jun 19 00:28:09.790" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:10.840" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 101[ms], 110[MiB]"
time="Jun 19 00:28:13.166" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:28:13.166" level=debug msg="**************** SingleInvoke invocationID min3.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:28:13.166" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.80[ms], 123[MiB]"
time="Jun 19 00:28:13.166" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 79661.04[ms]\n"
time="Jun 19 00:28:13.166" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.52] \n"
time="Jun 19 00:28:15.803" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:16.134" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:17.645" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:18.717" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:28:18.717" level=debug msg="**************** SingleInvoke invocationID min3.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:28:18.717" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.18[ms], 123[MiB]"
time="Jun 19 00:28:18.717" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 69738.78[ms]\n"
time="Jun 19 00:28:18.717" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.03] \n"
time="Jun 19 00:28:22.644" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 140[MiB]"
time="Jun 19 00:28:23.191" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:28.331" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:29.442" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:36.939" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:28:36.939" level=debug msg="**************** SingleInvoke invocationID min3.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:28:36.939" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.04[ms], 123[MiB]"
time="Jun 19 00:28:36.939" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 89655.93[ms]\n"
time="Jun 19 00:28:36.939" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.51] \n"
time="Jun 19 00:28:37.191" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:38.347" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:28:38.347" level=debug msg="**************** SingleInvoke invocationID min3.inv3, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:28:38.347" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.86[ms], 123[MiB]"
time="Jun 19 00:28:38.347" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 60349.94[ms]\n"
time="Jun 19 00:28:38.347" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.26] \n"
time="Jun 19 00:28:40.930" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 119[MiB]"
time="Jun 19 00:28:45.918" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:28:45.918" level=debug msg="**************** SingleInvoke invocationID min4.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:28:45.918" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.06[ms], 123[MiB]"
time="Jun 19 00:28:45.918" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 39842.47[ms]\n"
time="Jun 19 00:28:45.918" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.28] \n"
time="Jun 19 00:28:53.503" level=debug msg="End of minute 4\n"
time="Jun 19 00:28:53.503" level=debug msg="Start of minute 5\n"
time="Jun 19 00:28:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:53.506" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 112[MiB]"
time="Jun 19 00:28:53.506" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:54.275" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:28:54.476" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:28:54.477" level=debug msg="**************** SingleInvoke invocationID min4.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:28:54.477" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1009.19[ms], 123[MiB]"
time="Jun 19 00:28:54.477" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 60970.54[ms]\n"
time="Jun 19 00:28:54.477" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.09] \n"
time="Jun 19 00:29:01.659" level=debug msg="print minReplicas 4, iterations 500 "
time="Jun 19 00:29:01.659" level=debug msg="**************** SingleInvoke invocationID min4.inv1, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:29:01.659" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 1009.95[ms], 123[MiB]"
time="Jun 19 00:29:01.659" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 50818.66[ms]\n"
time="Jun 19 00:29:01.659" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.99] \n"
time="Jun 19 00:29:09.445" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:13.652" level=debug msg="print minReplicas 4, iterations 800 "
time="Jun 19 00:29:13.652" level=debug msg="**************** SingleInvoke invocationID min3.inv4, actual duration per iteration 100 [ms], response Time 3 [ms]"
time="Jun 19 00:29:13.653" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 1009.68[ms], 123[MiB]"
time="Jun 19 00:29:13.653" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 83122.63[ms]\n"
time="Jun 19 00:29:13.653" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.46] \n"
time="Jun 19 00:29:14.705" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:17.026" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:20.384" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:21.175" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:29:21.175" level=debug msg="**************** SingleInvoke invocationID min4.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:29:21.175" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.50[ms], 123[MiB]"
time="Jun 19 00:29:21.175" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 40244.71[ms]\n"
time="Jun 19 00:29:21.175" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.47] \n"
time="Jun 19 00:29:23.162" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:23.528" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:27.585" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 99[ms], 128[MiB]"
time="Jun 19 00:29:27.754" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:30.711" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 101[ms], 101[MiB]"
time="Jun 19 00:29:33.550" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:41.850" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:42.597" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 101[ms], 122[MiB]"
time="Jun 19 00:29:45.326" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:50.083" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:50.644" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 99[ms], 129[MiB]"
time="Jun 19 00:29:53.274" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:29:53.274" level=debug msg="**************** SingleInvoke invocationID min5.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:29:53.274" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.17[ms], 123[MiB]"
time="Jun 19 00:29:53.274" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 59767.64[ms]\n"
time="Jun 19 00:29:53.274" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.24] \n"
time="Jun 19 00:29:53.503" level=debug msg="End of minute 5\n"
time="Jun 19 00:29:53.503" level=debug msg="Start of minute 6\n"
time="Jun 19 00:29:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:53.507" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 115[MiB]"
time="Jun 19 00:29:54.099" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:29:54.099" level=debug msg="**************** SingleInvoke invocationID min4.inv3, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:29:54.099" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1009.41[ms], 123[MiB]"
time="Jun 19 00:29:54.099" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 91454.99[ms]\n"
time="Jun 19 00:29:54.099" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.04] \n"
time="Jun 19 00:29:55.184" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 126[MiB]"
time="Jun 19 00:29:58.041" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:29:58.405" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:07.130" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:13.011" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:22.269" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 124[MiB]"
time="Jun 19 00:30:23.693" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:30:23.693" level=debug msg="**************** SingleInvoke invocationID min6.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:30:23.693" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.38[ms], 123[MiB]"
time="Jun 19 00:30:23.693" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 30185.85[ms]\n"
time="Jun 19 00:30:23.693" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.75] \n"
time="Jun 19 00:30:24.093" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:26.989" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:30:27.482" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:28.973" level=debug msg="print minReplicas 8, iterations 200 "
time="Jun 19 00:30:28.974" level=debug msg="**************** SingleInvoke invocationID min5.inv1, actual duration per iteration 98 [ms], response Time 208 [ms]"
time="Jun 19 00:30:28.974" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 989.63[ms], 123[MiB]"
time="Jun 19 00:30:28.974" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 61388.46[ms]\n"
time="Jun 19 00:30:28.974" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.14] \n"
time="Jun 19 00:30:30.565" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:34.465" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:34.495" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:42.479" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 108[MiB]"
time="Jun 19 00:30:44.976" level=debug msg="print minReplicas 1, iterations 500 "
time="Jun 19 00:30:44.977" level=debug msg="**************** SingleInvoke invocationID min6.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:30:44.977" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.06[ms], 123[MiB]"
time="Jun 19 00:30:44.977" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 49792.18[ms]\n"
time="Jun 19 00:30:44.977" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.30] \n"
time="Jun 19 00:30:48.108" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:48.885" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:51.369" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:53.503" level=debug msg="End of minute 6\n"
time="Jun 19 00:30:53.503" level=debug msg="Start of minute 7\n"
time="Jun 19 00:30:53.507" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 100[ms], 117[MiB]"
time="Jun 19 00:30:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:53.507" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:30:55.404" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:01.822" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:04.021" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:05.489" level=debug msg="print minReplicas 2, iterations 100 "
time="Jun 19 00:31:05.489" level=debug msg="**************** SingleInvoke invocationID min7.inv0, actual duration per iteration 99 [ms], response Time 20 [ms]"
time="Jun 19 00:31:05.490" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 999.86[ms], 123[MiB]"
time="Jun 19 00:31:05.490" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 11982.36[ms]\n"
time="Jun 19 00:31:05.490" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.95] \n"
time="Jun 19 00:31:05.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:09.022" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 104[MiB]"
time="Jun 19 00:31:09.498" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:10.294" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:15.428" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 113[MiB]"
time="Jun 19 00:31:18.932" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 100[ms], 122[MiB]"
time="Jun 19 00:31:20.089" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:29.605" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:30.979" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:31:30.979" level=debug msg="**************** SingleInvoke invocationID min6.inv2, actual duration per iteration 99 [ms], response Time 15 [ms]"
time="Jun 19 00:31:30.979" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 999.94[ms], 123[MiB]"
time="Jun 19 00:31:30.979" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 68710.25[ms]\n"
time="Jun 19 00:31:30.980" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.95] \n"
time="Jun 19 00:31:33.422" level=debug msg="print minReplicas 8, iterations 300 "
time="Jun 19 00:31:33.422" level=debug msg="**************** SingleInvoke invocationID min5.inv4, actual duration per iteration 98 [ms], response Time 244 [ms]"
time="Jun 19 00:31:33.422" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 989.83[ms], 123[MiB]"
time="Jun 19 00:31:33.422" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 102778.21[ms]\n"
time="Jun 19 00:31:33.422" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.90] \n"
time="Jun 19 00:31:33.513" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 115[MiB]"
time="Jun 19 00:31:36.626" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:38.196" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:46.651" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:31:46.651" level=debug msg="**************** SingleInvoke invocationID min6.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:31:46.651" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.96[ms], 123[MiB]"
time="Jun 19 00:31:46.651" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 79662.02[ms]\n"
time="Jun 19 00:31:46.651" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.09] \n"
time="Jun 19 00:31:48.851" level=debug msg="print minReplicas 1, iterations 400 "
time="Jun 19 00:31:48.851" level=debug msg="**************** SingleInvoke invocationID min7.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:31:48.851" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.13[ms], 123[MiB]"
time="Jun 19 00:31:48.852" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 39829.40[ms]\n"
time="Jun 19 00:31:48.852" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.73] \n"
time="Jun 19 00:31:49.602" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:53.442" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:53.502" level=debug msg="End of minute 7\n"
time="Jun 19 00:31:53.502" level=debug msg="Start of minute 8\n"
time="Jun 19 00:31:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:31:53.508" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 114[MiB]"
time="Jun 19 00:31:56.658" level=debug msg="print minReplicas 8, iterations 400 "
time="Jun 19 00:31:56.658" level=debug msg="**************** SingleInvoke invocationID min5.inv3, actual duration per iteration 100 [ms], response Time 235 [ms]"
time="Jun 19 00:31:56.658" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 1009.55[ms], 123[MiB]"
time="Jun 19 00:31:56.658" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 134060.73[ms]\n"
time="Jun 19 00:31:56.658" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.56] \n"
time="Jun 19 00:31:59.137" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:00.574" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 114[MiB]"
time="Jun 19 00:32:02.356" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:32:02.356" level=debug msg="**************** SingleInvoke invocationID min6.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:32:02.356" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.47[ms], 123[MiB]"
time="Jun 19 00:32:02.356" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 79877.22[ms]\n"
time="Jun 19 00:32:02.356" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.38] \n"
time="Jun 19 00:32:05.707" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 116[MiB]"
time="Jun 19 00:32:05.746" level=debug msg="print minReplicas 8, iterations 500 "
time="Jun 19 00:32:05.746" level=debug msg="**************** SingleInvoke invocationID min5.inv2, actual duration per iteration 100 [ms], response Time 210 [ms]"
time="Jun 19 00:32:05.746" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 1010.06[ms], 123[MiB]"
time="Jun 19 00:32:05.746" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 155035.10[ms]\n"
time="Jun 19 00:32:05.746" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [5.99] \n"
time="Jun 19 00:32:09.476" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:09.921" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:25.760" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:28.289" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:31.049" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:32:31.049" level=debug msg="**************** SingleInvoke invocationID min8.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:32:31.049" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1009.20[ms], 123[MiB]"
time="Jun 19 00:32:31.049" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 30475.50[ms]\n"
time="Jun 19 00:32:31.049" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-7.29] \n"
time="Jun 19 00:32:33.275" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:32:33.275" level=debug msg="**************** SingleInvoke invocationID min7.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:32:33.276" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.74[ms], 123[MiB]"
time="Jun 19 00:32:33.276" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 59762.09[ms]\n"
time="Jun 19 00:32:33.276" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.64] \n"
time="Jun 19 00:32:35.087" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:32:35.087" level=debug msg="**************** SingleInvoke invocationID min7.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:32:35.087" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.17[ms], 123[MiB]"
time="Jun 19 00:32:35.087" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 79658.94[ms]\n"
time="Jun 19 00:32:35.087" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.35] \n"
time="Jun 19 00:32:41.825" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:43.866" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:44.377" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 114[MiB]"
time="Jun 19 00:32:50.420" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:50.997" level=debug msg="print minReplicas 8, iterations 600 "
time="Jun 19 00:32:50.997" level=debug msg="**************** SingleInvoke invocationID min7.inv2, actual duration per iteration 99 [ms], response Time 54 [ms]"
time="Jun 19 00:32:50.997" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 999.70[ms], 123[MiB]"
time="Jun 19 00:32:50.997" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 92064.96[ms]\n"
time="Jun 19 00:32:50.997" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.54] \n"
time="Jun 19 00:32:51.007" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:51.202" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 100[ms], 134[MiB]"
time="Jun 19 00:32:52.219" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:52.465" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:52.595" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:53.503" level=debug msg="End of minute 8\n"
time="Jun 19 00:32:53.503" level=debug msg="Start of minute 9\n"
time="Jun 19 00:32:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:53.508" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 130[MiB]"
time="Jun 19 00:32:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:53.508" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:53.854" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:32:53.855" level=debug msg="**************** SingleInvoke invocationID min8.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:32:53.855" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.10[ms], 123[MiB]"
time="Jun 19 00:32:53.855" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 60346.60[ms]\n"
time="Jun 19 00:32:53.855" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.83] \n"
time="Jun 19 00:32:54.124" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:32:58.825" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 118[MiB]"
time="Jun 19 00:33:07.182" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:14.268" level=debug msg="print minReplicas 2, iterations 300 "
time="Jun 19 00:33:14.268" level=debug msg="**************** SingleInvoke invocationID min8.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:33:14.268" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 990.04[ms], 123[MiB]"
time="Jun 19 00:33:14.268" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 29890.10[ms]\n"
time="Jun 19 00:33:14.268" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.73] \n"
time="Jun 19 00:33:19.479" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:21.410" level=debug msg="print minReplicas 2, iterations 300 "
time="Jun 19 00:33:21.410" level=debug msg="**************** SingleInvoke invocationID min8.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:33:21.410" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 999.77[ms], 123[MiB]"
time="Jun 19 00:33:21.410" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 30207.80[ms]\n"
time="Jun 19 00:33:21.410" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.54] \n"
time="Jun 19 00:33:22.782" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:25.109" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:25.407" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:33:25.407" level=debug msg="**************** SingleInvoke invocationID min8.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:33:25.407" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.65[ms], 123[MiB]"
time="Jun 19 00:33:25.407" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 79699.67[ms]\n"
time="Jun 19 00:33:25.407" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.22] \n"
time="Jun 19 00:33:26.910" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:27.380" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 100[ms], 128[MiB]"
time="Jun 19 00:33:28.489" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:30.467" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 101[ms], 123[MiB]"
time="Jun 19 00:33:34.413" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:35.640" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:43.536" level=debug msg="print minReplicas 8, iterations 100 "
time="Jun 19 00:33:43.536" level=debug msg="**************** SingleInvoke invocationID min9.inv2, actual duration per iteration 99 [ms], response Time 62 [ms]"
time="Jun 19 00:33:43.536" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 999.70[ms], 123[MiB]"
time="Jun 19 00:33:43.536" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 16155.44[ms]\n"
time="Jun 19 00:33:43.536" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.50] \n"
time="Jun 19 00:33:47.736" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 100[ms], 125[MiB]"
time="Jun 19 00:33:48.004" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:48.624" level=debug msg="print minReplicas 4, iterations 500 "
time="Jun 19 00:33:48.625" level=debug msg="**************** SingleInvoke invocationID min9.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:33:48.625" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.22[ms], 123[MiB]"
time="Jun 19 00:33:48.625" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 49799.20[ms]\n"
time="Jun 19 00:33:48.625" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.07] \n"
time="Jun 19 00:33:50.219" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:52.300" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:53.502" level=debug msg="End of minute 9\n"
time="Jun 19 00:33:53.503" level=debug msg="Start of minute 10\n"
time="Jun 19 00:33:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:53.509" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 110[MiB]"
time="Jun 19 00:33:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:33:54.777" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 101[ms], 126[MiB]"
time="Jun 19 00:33:57.354" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:01.089" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:07.908" level=debug msg="print minReplicas 8, iterations 300 "
time="Jun 19 00:34:07.908" level=debug msg="**************** SingleInvoke invocationID min9.inv3, actual duration per iteration 100 [ms], response Time 24 [ms]"
time="Jun 19 00:34:07.908" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 1010.08[ms], 123[MiB]"
time="Jun 19 00:34:07.908" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 37440.63[ms]\n"
time="Jun 19 00:34:07.908" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [7.27] \n"
time="Jun 19 00:34:08.790" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 123[MiB]"
time="Jun 19 00:34:10.052" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:11.489" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:16.635" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:21.682" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:23.161" level=debug msg="print minReplicas 1, iterations 900 "
time="Jun 19 00:34:23.161" level=debug msg="**************** SingleInvoke invocationID min9.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:34:23.161" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.06[ms], 123[MiB]"
time="Jun 19 00:34:23.162" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 89652.96[ms]\n"
time="Jun 19 00:34:23.162" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.57] \n"
time="Jun 19 00:34:26.267" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:26.887" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 100[MiB]"
time="Jun 19 00:34:29.119" level=debug msg="print minReplicas 2, iterations 200 "
time="Jun 19 00:34:29.119" level=debug msg="**************** SingleInvoke invocationID min10.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:34:29.119" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.08[ms], 123[MiB]"
time="Jun 19 00:34:29.119" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 20329.30[ms]\n"
time="Jun 19 00:34:29.120" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.12] \n"
time="Jun 19 00:34:34.181" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:35.416" level=debug msg="print minReplicas 4, iterations 400 "
time="Jun 19 00:34:35.416" level=debug msg="**************** SingleInvoke invocationID min10.inv1, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:34:35.416" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 1009.46[ms], 123[MiB]"
time="Jun 19 00:34:35.416" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 40638.72[ms]\n"
time="Jun 19 00:34:35.416" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.04] \n"
time="Jun 19 00:34:39.322" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:44.063" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 110[MiB]"
time="Jun 19 00:34:49.894" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:51.404" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:53.190" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:53.503" level=debug msg="End of minute 10\n"
time="Jun 19 00:34:53.503" level=debug msg="Start of minute 11\n"
time="Jun 19 00:34:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:34:53.509" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 101[ms], 117[MiB]"
time="Jun 19 00:34:54.033" level=debug msg="print minReplicas 1, iterations 100 "
time="Jun 19 00:34:54.033" level=debug msg="**************** SingleInvoke invocationID min10.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:34:54.033" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.10[ms], 123[MiB]"
time="Jun 19 00:34:54.033" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 9969.49[ms]\n"
time="Jun 19 00:34:54.033" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.75] \n"
time="Jun 19 00:35:00.989" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:03.940" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:35:03.940" level=debug msg="**************** SingleInvoke invocationID min10.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:35:03.940" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.20[ms], 123[MiB]"
time="Jun 19 00:35:03.940" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 70430.46[ms]\n"
time="Jun 19 00:35:03.940" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-3.24] \n"
time="Jun 19 00:35:05.909" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:08.210" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:35:08.210" level=debug msg="**************** SingleInvoke invocationID min9.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:35:08.210" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1000.16[ms], 123[MiB]"
time="Jun 19 00:35:08.210" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 80473.76[ms]\n"
time="Jun 19 00:35:08.210" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.42] \n"
time="Jun 19 00:35:11.955" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 108[MiB]"
time="Jun 19 00:35:13.978" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:14.383" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:20.716" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 101[MiB]"
time="Jun 19 00:35:21.022" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:21.611" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:23.932" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:29.013" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 111[MiB]"
time="Jun 19 00:35:30.061" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:31.788" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:32.597" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:34.170" level=debug msg="print minReplicas 8, iterations 400 "
time="Jun 19 00:35:34.170" level=debug msg="**************** SingleInvoke invocationID min11.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:35:34.170" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 1009.51[ms], 123[MiB]"
time="Jun 19 00:35:34.170" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 40660.58[ms]\n"
time="Jun 19 00:35:34.170" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.18] \n"
time="Jun 19 00:35:36.617" level=debug msg="print minReplicas 4, iterations 700 "
time="Jun 19 00:35:36.617" level=debug msg="**************** SingleInvoke invocationID min10.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:35:36.617" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.05[ms], 123[MiB]"
time="Jun 19 00:35:36.617" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 69729.58[ms]\n"
time="Jun 19 00:35:36.617" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.96] \n"
time="Jun 19 00:35:38.079" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:39.807" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 119[MiB]"
time="Jun 19 00:35:50.514" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:53.503" level=debug msg="End of minute 11\n"
time="Jun 19 00:35:53.503" level=debug msg="Start of minute 12\n"
time="Jun 19 00:35:53.509" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 112[MiB]"
time="Jun 19 00:35:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:53.509" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:57.744" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:35:59.503" level=debug msg="print minReplicas 2, iterations 300 "
time="Jun 19 00:35:59.503" level=debug msg="**************** SingleInvoke invocationID min11.inv3, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:35:59.503" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.75[ms], 123[MiB]"
time="Jun 19 00:35:59.503" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 30490.17[ms]\n"
time="Jun 19 00:35:59.503" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.56] \n"
time="Jun 19 00:36:00.966" level=debug msg="print minReplicas 4, iterations 400 "
time="Jun 19 00:36:00.966" level=debug msg="**************** SingleInvoke invocationID min11.inv1, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:36:00.966" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 1000.19[ms], 123[MiB]"
time="Jun 19 00:36:00.966" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 40249.69[ms]\n"
time="Jun 19 00:36:00.966" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.82] \n"
time="Jun 19 00:36:02.946" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 109[MiB]"
time="Jun 19 00:36:08.757" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:10.533" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:11.135" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:13.013" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 119[MiB]"
time="Jun 19 00:36:15.592" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:30.195" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:30.439" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:31.157" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 132[MiB]"
time="Jun 19 00:36:32.851" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:36:32.851" level=debug msg="**************** SingleInvoke invocationID min12.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:36:32.851" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.99[ms], 123[MiB]"
time="Jun 19 00:36:32.851" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 29904.57[ms]\n"
time="Jun 19 00:36:32.851" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-3.27] \n"
time="Jun 19 00:36:33.250" level=debug msg="print minReplicas 2, iterations 800 "
time="Jun 19 00:36:33.250" level=debug msg="**************** SingleInvoke invocationID min11.inv2, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:36:33.250" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.70[ms], 123[MiB]"
time="Jun 19 00:36:33.250" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 81294.97[ms]\n"
time="Jun 19 00:36:33.250" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.46] \n"
time="Jun 19 00:36:34.799" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:39.128" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:39.342" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 114[MiB]"
time="Jun 19 00:36:41.110" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:41.302" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:52.035" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:53.502" level=debug msg="End of minute 12\n"
time="Jun 19 00:36:53.502" level=debug msg="Start of minute 13\n"
time="Jun 19 00:36:53.510" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:53.510" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:53.510" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:36:53.511" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 126[MiB]"
time="Jun 19 00:36:53.768" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:00.961" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:01.045" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:37:01.045" level=debug msg="**************** SingleInvoke invocationID min12.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:37:01.045" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.45[ms], 123[MiB]"
time="Jun 19 00:37:01.045" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 29887.92[ms]\n"
time="Jun 19 00:37:01.045" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.60] \n"
time="Jun 19 00:37:02.011" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 126[MiB]"
time="Jun 19 00:37:03.479" level=debug msg="print minReplicas 2, iterations 100 "
time="Jun 19 00:37:03.479" level=debug msg="**************** SingleInvoke invocationID min13.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:37:03.479" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.41[ms], 123[MiB]"
time="Jun 19 00:37:03.479" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 9968.45[ms]\n"
time="Jun 19 00:37:03.479" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.82] \n"
time="Jun 19 00:37:07.599" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:08.084" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:08.780" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:09.928" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:11.264" level=debug msg="print minReplicas 2, iterations 900 "
time="Jun 19 00:37:11.264" level=debug msg="**************** SingleInvoke invocationID min11.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:37:11.264" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.06[ms], 123[MiB]"
time="Jun 19 00:37:11.264" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 91456.42[ms]\n"
time="Jun 19 00:37:11.264" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.78] \n"
time="Jun 19 00:37:13.375" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:37:13.375" level=debug msg="**************** SingleInvoke invocationID min12.inv3, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:37:13.375" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 999.51[ms], 123[MiB]"
time="Jun 19 00:37:13.375" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 60361.79[ms]\n"
time="Jun 19 00:37:13.375" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-3.73] \n"
time="Jun 19 00:37:15.735" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:23.226" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:24.945" level=debug msg="print minReplicas 2, iterations 900 "
time="Jun 19 00:37:24.945" level=debug msg="**************** SingleInvoke invocationID min12.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:37:24.945" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1010.10[ms], 123[MiB]"
time="Jun 19 00:37:24.945" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 91435.85[ms]\n"
time="Jun 19 00:37:24.945" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.52] \n"
time="Jun 19 00:37:28.427" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 134[MiB]"
time="Jun 19 00:37:31.611" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:34.982" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 125[MiB]"
time="Jun 19 00:37:35.273" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:38.167" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 101[ms], 130[MiB]"
time="Jun 19 00:37:40.218" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:48.348" level=debug msg="print minReplicas 4, iterations 200 "
time="Jun 19 00:37:48.348" level=debug msg="**************** SingleInvoke invocationID min13.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:37:48.348" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.14[ms], 123[MiB]"
time="Jun 19 00:37:48.348" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 19921.11[ms]\n"
time="Jun 19 00:37:48.349" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.96] \n"
time="Jun 19 00:37:50.660" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:53.502" level=debug msg="End of minute 13\n"
time="Jun 19 00:37:53.502" level=debug msg="Start of minute 14\n"
time="Jun 19 00:37:53.511" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-8: 99[ms], 135[MiB]"
time="Jun 19 00:37:53.511" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:53.511" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:53.511" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:58.455" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:37:59.010" level=debug msg="print minReplicas 1, iterations 800 "
time="Jun 19 00:37:59.010" level=debug msg="**************** SingleInvoke invocationID min12.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:37:59.010" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.31[ms], 123[MiB]"
time="Jun 19 00:37:59.010" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 79667.66[ms]\n"
time="Jun 19 00:37:59.010" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.71] \n"
time="Jun 19 00:38:00.386" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:04.726" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:04.875" level=debug msg="print minReplicas 4, iterations 300 "
time="Jun 19 00:38:04.875" level=debug msg="**************** SingleInvoke invocationID min13.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:38:04.875" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.58[ms], 123[MiB]"
time="Jun 19 00:38:04.875" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 29892.96[ms]\n"
time="Jun 19 00:38:04.875" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-5.70] \n"
time="Jun 19 00:38:06.566" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:07.522" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:11.742" level=debug msg="print minReplicas 2, iterations 700 "
time="Jun 19 00:38:11.742" level=debug msg="**************** SingleInvoke invocationID min13.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:38:11.742" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 990.11[ms], 123[MiB]"
time="Jun 19 00:38:11.742" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 69731.01[ms]\n"
time="Jun 19 00:38:11.742" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.51] \n"
time="Jun 19 00:38:20.546" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 116[MiB]"
time="Jun 19 00:38:23.161" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:27.421" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 107[MiB]"
time="Jun 19 00:38:27.548" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:30.984" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 123[MiB]"
time="Jun 19 00:38:31.295" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:40.029" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:40.949" level=debug msg="print minReplicas 1, iterations 100 "
time="Jun 19 00:38:40.950" level=debug msg="**************** SingleInvoke invocationID min14.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:38:40.950" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.87[ms], 123[MiB]"
time="Jun 19 00:38:40.950" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 9965.58[ms]\n"
time="Jun 19 00:38:40.950" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.99] \n"
time="Jun 19 00:38:41.909" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:42.590" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:44.308" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 123[MiB]"
time="Jun 19 00:38:49.067" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:49.295" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:38:49.295" level=debug msg="**************** SingleInvoke invocationID min13.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:38:49.295" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1010.09[ms], 123[MiB]"
time="Jun 19 00:38:49.295" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 71127.45[ms]\n"
time="Jun 19 00:38:49.295" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-3.85] \n"
time="Jun 19 00:38:53.503" level=debug msg="End of minute 14\n"
time="Jun 19 00:38:53.503" level=debug msg="Start of minute 15\n"
time="Jun 19 00:38:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:38:53.512" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 101[MiB]"
time="Jun 19 00:38:55.536" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 129[MiB]"
time="Jun 19 00:38:57.329" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:38:57.329" level=debug msg="**************** SingleInvoke invocationID min14.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:38:57.329" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.29[ms], 123[MiB]"
time="Jun 19 00:38:57.329" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 29908.37[ms]\n"
time="Jun 19 00:38:57.329" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.67] \n"
time="Jun 19 00:38:59.440" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 119[MiB]"
time="Jun 19 00:39:01.695" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:13.059" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:15.170" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:15.229" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:16.838" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:18.205" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:20.298" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:39:20.298" level=debug msg="**************** SingleInvoke invocationID min14.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:39:20.298" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.46[ms], 123[MiB]"
time="Jun 19 00:39:20.298" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 59751.78[ms]\n"
time="Jun 19 00:39:20.298" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.37] \n"
time="Jun 19 00:39:22.102" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:23.391" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:39:23.391" level=debug msg="**************** SingleInvoke invocationID min15.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:39:23.391" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.32[ms], 123[MiB]"
time="Jun 19 00:39:23.391" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 29879.22[ms]\n"
time="Jun 19 00:39:23.391" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [3.43] \n"
time="Jun 19 00:39:25.383" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:25.408" level=debug msg="print minReplicas 1, iterations 300 "
time="Jun 19 00:39:25.408" level=debug msg="**************** SingleInvoke invocationID min15.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:39:25.408" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 990.08[ms], 123[MiB]"
time="Jun 19 00:39:25.408" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 29871.84[ms]\n"
time="Jun 19 00:39:25.409" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.75] \n"
time="Jun 19 00:39:35.118" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:39.664" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:42.087" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 124[MiB]"
time="Jun 19 00:39:45.301" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:46.340" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 122[MiB]"
time="Jun 19 00:39:51.129" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:53.503" level=debug msg="End of minute 15\n"
time="Jun 19 00:39:53.503" level=debug msg="Start of minute 16\n"
time="Jun 19 00:39:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:53.512" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:53.512" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 142[MiB]"
time="Jun 19 00:39:54.794" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:39:59.800" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:39:59.800" level=debug msg="**************** SingleInvoke invocationID min15.inv2, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:39:59.800" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 1000.05[ms], 123[MiB]"
time="Jun 19 00:39:59.800" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 60360.39[ms]\n"
time="Jun 19 00:39:59.800" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.61] \n"
time="Jun 19 00:40:01.543" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:04.755" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 100[ms], 118[MiB]"
time="Jun 19 00:40:15.748" level=debug msg="print minReplicas 2, iterations 900 "
time="Jun 19 00:40:15.748" level=debug msg="**************** SingleInvoke invocationID min14.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:40:15.748" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1010.12[ms], 123[MiB]"
time="Jun 19 00:40:15.748" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 91439.60[ms]\n"
time="Jun 19 00:40:15.748" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.75] \n"
time="Jun 19 00:40:18.534" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:20.447" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:24.874" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:40:24.874" level=debug msg="**************** SingleInvoke invocationID min16.inv1, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:40:24.874" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.70[ms], 123[MiB]"
time="Jun 19 00:40:24.874" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 20119.11[ms]\n"
time="Jun 19 00:40:24.874" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.57] \n"
time="Jun 19 00:40:31.864" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 133[MiB]"
time="Jun 19 00:40:35.447" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 121[MiB]"
time="Jun 19 00:40:39.991" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:43.109" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:43.801" level=debug msg="print minReplicas 1, iterations 500 "
time="Jun 19 00:40:43.801" level=debug msg="**************** SingleInvoke invocationID min16.inv0, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:40:43.801" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 999.99[ms], 123[MiB]"
time="Jun 19 00:40:43.801" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 50288.18[ms]\n"
time="Jun 19 00:40:43.801" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.80] \n"
time="Jun 19 00:40:44.274" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:44.737" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:46.966" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:47.505" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:52.094" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 100[MiB]"
time="Jun 19 00:40:52.191" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:52.808" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:53.503" level=debug msg="End of minute 16\n"
time="Jun 19 00:40:53.503" level=debug msg="Start of minute 17\n"
time="Jun 19 00:40:53.513" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:53.513" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:53.513" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:53.513" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 121[MiB]"
time="Jun 19 00:40:56.070" level=debug msg="print minReplicas 2, iterations 700 "
time="Jun 19 00:40:56.070" level=debug msg="**************** SingleInvoke invocationID min15.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:40:56.070" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.59[ms], 123[MiB]"
time="Jun 19 00:40:56.070" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 69730.00[ms]\n"
time="Jun 19 00:40:56.070" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.56] \n"
time="Jun 19 00:40:56.230" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:40:57.358" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:01.741" level=debug msg="print minReplicas 4, iterations 800 "
time="Jun 19 00:41:01.741" level=debug msg="**************** SingleInvoke invocationID min15.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:41:01.741" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.26[ms], 123[MiB]"
time="Jun 19 00:41:01.741" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 79654.10[ms]\n"
time="Jun 19 00:41:01.741" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.72] \n"
time="Jun 19 00:41:04.965" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 101[MiB]"
time="Jun 19 00:41:05.094" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 123[MiB]"
time="Jun 19 00:41:06.193" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:09.340" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:09.807" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:14.468" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 118[MiB]"
time="Jun 19 00:41:15.632" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:20.524" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:21.691" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:22.258" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 105[MiB]"
time="Jun 19 00:41:23.610" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:25.015" level=debug msg="print minReplicas 2, iterations 200 "
time="Jun 19 00:41:25.016" level=debug msg="**************** SingleInvoke invocationID min17.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:41:25.016" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.34[ms], 123[MiB]"
time="Jun 19 00:41:25.016" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 19920.99[ms]\n"
time="Jun 19 00:41:25.016" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-6.66] \n"
time="Jun 19 00:41:28.584" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:31.951" level=debug msg="print minReplicas 4, iterations 400 "
time="Jun 19 00:41:31.951" level=debug msg="**************** SingleInvoke invocationID min16.inv4, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:41:31.951" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.37[ms], 123[MiB]"
time="Jun 19 00:41:31.951" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 39857.26[ms]\n"
time="Jun 19 00:41:31.952" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.34] \n"
time="Jun 19 00:41:34.143" level=debug msg="print minReplicas 2, iterations 400 "
time="Jun 19 00:41:34.143" level=debug msg="**************** SingleInvoke invocationID min17.inv0, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:41:34.143" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.88[ms], 123[MiB]"
time="Jun 19 00:41:34.143" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 40629.31[ms]\n"
time="Jun 19 00:41:34.143" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.79] \n"
time="Jun 19 00:41:35.189" level=debug msg="print minReplicas 1, iterations 600 "
time="Jun 19 00:41:35.189" level=debug msg="**************** SingleInvoke invocationID min16.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:41:35.189" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.89[ms], 123[MiB]"
time="Jun 19 00:41:35.189" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 59742.09[ms]\n"
time="Jun 19 00:41:35.189" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-5.83] \n"
time="Jun 19 00:41:38.998" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:42.262" level=debug msg="print minReplicas 4, iterations 700 "
time="Jun 19 00:41:42.262" level=debug msg="**************** SingleInvoke invocationID min16.inv2, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:41:42.262" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 999.52[ms], 123[MiB]"
time="Jun 19 00:41:42.262" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 70397.84[ms]\n"
time="Jun 19 00:41:42.262" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.05] \n"
time="Jun 19 00:41:45.511" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:53.503" level=debug msg="End of minute 17\n"
time="Jun 19 00:41:53.503" level=debug msg="Start of minute 18\n"
time="Jun 19 00:41:53.514" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:53.514" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:53.514" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:41:53.514" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 125[MiB]"
time="Jun 19 00:41:54.529" level=debug msg="print minReplicas 4, iterations 400 "
time="Jun 19 00:41:54.529" level=debug msg="**************** SingleInvoke invocationID min17.inv3, actual duration per iteration 98 [ms], response Time 2 [ms]"
time="Jun 19 00:41:54.530" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.48[ms], 123[MiB]"
time="Jun 19 00:41:54.530" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 40061.01[ms]\n"
time="Jun 19 00:41:54.530" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.52] \n"
time="Jun 19 00:42:00.297" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:01.636" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:05.260" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:05.525" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:12.647" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:14.560" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 124[MiB]"
time="Jun 19 00:42:14.668" level=debug msg="print minReplicas 1, iterations 700 "
time="Jun 19 00:42:14.668" level=debug msg="**************** SingleInvoke invocationID min17.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:42:14.668" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.96[ms], 123[MiB]"
time="Jun 19 00:42:14.668" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 69702.98[ms]\n"
time="Jun 19 00:42:14.668" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.98] \n"
time="Jun 19 00:42:20.021" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:20.246" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:20.749" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 99[ms], 115[MiB]"
time="Jun 19 00:42:23.211" level=debug msg="print minReplicas 2, iterations 600 "
time="Jun 19 00:42:23.212" level=debug msg="**************** SingleInvoke invocationID min17.inv4, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:42:23.212" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1009.24[ms], 123[MiB]"
time="Jun 19 00:42:23.212" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 60953.20[ms]\n"
time="Jun 19 00:42:23.212" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-0.26] \n"
time="Jun 19 00:42:24.792" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:25.763" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:26.531" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-1: 99[ms], 129[MiB]"
time="Jun 19 00:42:39.066" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:40.679" level=debug msg="print minReplicas 2, iterations 200 "
time="Jun 19 00:42:40.679" level=debug msg="**************** SingleInvoke invocationID min18.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:42:40.679" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.92[ms], 123[MiB]"
time="Jun 19 00:42:40.679" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 19929.52[ms]\n"
time="Jun 19 00:42:40.679" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.88] \n"
time="Jun 19 00:42:43.331" level=debug msg="print minReplicas 2, iterations 500 "
time="Jun 19 00:42:43.331" level=debug msg="**************** SingleInvoke invocationID min18.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:42:43.331" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.50[ms], 123[MiB]"
time="Jun 19 00:42:43.331" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 49816.77[ms]\n"
time="Jun 19 00:42:43.331" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-1.96] \n"
time="Jun 19 00:42:46.455" level=debug msg="print minReplicas 1, iterations 200 "
time="Jun 19 00:42:46.455" level=debug msg="**************** SingleInvoke invocationID min18.inv3, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:42:46.455" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-1: this is reply, 989.54[ms], 123[MiB]"
time="Jun 19 00:42:46.455" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-1: 19924.47[ms]\n"
time="Jun 19 00:42:46.455" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.06] \n"
time="Jun 19 00:42:50.500" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:51.255" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 132[MiB]"
time="Jun 19 00:42:52.546" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:53.502" level=debug msg="End of minute 18\n"
time="Jun 19 00:42:53.502" level=debug msg="Start of minute 19\n"
time="Jun 19 00:42:53.515" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:53.515" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:53.515" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:53.515" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 135[MiB]"
time="Jun 19 00:42:54.404" level=debug msg="print minReplicas 2, iterations 400 "
time="Jun 19 00:42:54.404" level=debug msg="**************** SingleInvoke invocationID min18.inv1, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:42:54.404" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 989.84[ms], 123[MiB]"
time="Jun 19 00:42:54.404" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 39843.41[ms]\n"
time="Jun 19 00:42:54.404" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [6.23] \n"
time="Jun 19 00:42:55.600" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:59.067" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:59.615" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:42:59.695" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:13.478" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 100[ms], 121[MiB]"
time="Jun 19 00:43:17.157" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:22.711" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-2: 101[ms], 134[MiB]"
time="Jun 19 00:43:23.403" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 99[ms], 126[MiB]"
time="Jun 19 00:43:27.539" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:29.387" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:33.357" level=debug msg="print minReplicas 4, iterations 400 "
time="Jun 19 00:43:33.357" level=debug msg="**************** SingleInvoke invocationID min19.inv0, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:43:33.357" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 989.13[ms], 123[MiB]"
time="Jun 19 00:43:33.357" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 39841.96[ms]\n"
time="Jun 19 00:43:33.357" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [2.24] \n"
time="Jun 19 00:43:33.578" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:37.161" level=trace msg="(Invoke)\t gpttrace-func-0-8919973466490155915-gpu-4: 100[ms], 118[MiB]"
time="Jun 19 00:43:37.288" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:41.572" level=debug msg="print minReplicas 4, iterations 500 "
time="Jun 19 00:43:41.572" level=debug msg="**************** SingleInvoke invocationID min18.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:43:41.572" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 999.39[ms], 123[MiB]"
time="Jun 19 00:43:41.573" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 50317.31[ms]\n"
time="Jun 19 00:43:41.573" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [4.08] \n"
time="Jun 19 00:43:41.880" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:43.340" level=debug msg="print minReplicas 4, iterations 200 "
time="Jun 19 00:43:43.340" level=debug msg="**************** SingleInvoke invocationID min19.inv2, actual duration per iteration 98 [ms], response Time 1 [ms]"
time="Jun 19 00:43:43.340" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 990.21[ms], 123[MiB]"
time="Jun 19 00:43:43.340" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 19937.02[ms]\n"
time="Jun 19 00:43:43.340" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-4.44] \n"
time="Jun 19 00:43:48.794" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:50.443" level=debug msg="Test mode invocation fired.\n"
time="Jun 19 00:43:53.502" level=debug msg="End of minute 19\n"
time="Jun 19 00:43:53.515" level=debug msg="All the invocations for function gpttrace-func-0-8919973466490155915-gpu-1 have been completed.\n"
time="Jun 19 00:44:03.775" level=debug msg="print minReplicas 2, iterations 500 "
time="Jun 19 00:44:03.775" level=debug msg="**************** SingleInvoke invocationID min19.inv1, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:44:03.775" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1000.06[ms], 123[MiB]"
time="Jun 19 00:44:03.775" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 50296.88[ms]\n"
time="Jun 19 00:44:03.775" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [0.19] \n"
time="Jun 19 00:44:33.835" level=debug msg="print minReplicas 2, iterations 700 "
time="Jun 19 00:44:33.835" level=debug msg="**************** SingleInvoke invocationID min19.inv3, actual duration per iteration 100 [ms], response Time 1 [ms]"
time="Jun 19 00:44:33.835" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-2: this is reply, 1010.13[ms], 123[MiB]"
time="Jun 19 00:44:33.835" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-2: 71124.24[ms]\n"
time="Jun 19 00:44:33.835" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-3.07] \n"
time="Jun 19 00:44:33.836" level=debug msg="All the invocations for function gpttrace-func-0-8919973466490155915-gpu-2 have been completed.\n"
time="Jun 19 00:44:37.544" level=debug msg="print minReplicas 4, iterations 600 "
time="Jun 19 00:44:37.544" level=debug msg="**************** SingleInvoke invocationID min19.inv4, actual duration per iteration 99 [ms], response Time 1 [ms]"
time="Jun 19 00:44:37.544" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-4: this is reply, 1000.02[ms], 123[MiB]"
time="Jun 19 00:44:37.544" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-4: 60382.97[ms]\n"
time="Jun 19 00:44:37.544" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [-2.58] \n"
time="Jun 19 00:44:37.544" level=debug msg="All the invocations for function gpttrace-func-0-8919973466490155915-gpu-4 have been completed.\n"
time="Jun 19 00:47:35.736" level=debug msg="print minReplicas 8, iterations 900 "
time="Jun 19 00:47:35.736" level=debug msg="**************** SingleInvoke invocationID min14.inv0, actual duration per iteration 98 [ms], response Time 548 [ms]"
time="Jun 19 00:47:35.736" level=trace msg="(Replied)\t gpttrace-func-0-8919973466490155915-gpu-8: this is reply, 989.67[ms], 123[MiB]"
time="Jun 19 00:47:35.736" level=trace msg="(E2E Latency) gpttrace-func-0-8919973466490155915-gpu-8: 582224.88[ms]\n"
time="Jun 19 00:47:35.736" level=trace msg="Length of Prompt Tensor [128] \t Sum of Prompt Tensor [1.13] \n"
time="Jun 19 00:47:35.737" level=debug msg="All the invocations for function gpttrace-func-0-8919973466490155915-gpu-8 have been completed.\n"
time="Jun 19 00:47:35.737" level=debug msg="Waiting for all the invocations record to be written.\n"
time="Jun 19 00:47:35.737" level=info msg="Trace has finished executing function invocation driver\n"
time="Jun 19 00:47:35.737" level=info msg="Number of successful invocations: \t400\n"
time="Jun 19 00:47:35.737" level=info msg="Number of failed invocations: \t0\n"
