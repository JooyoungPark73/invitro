$ kn service list
NAME           URL                                                  LATEST               AGE    CONDITIONS   READY   REASON
trace-func-0   http://trace-func-0.default.192.168.1.240.sslip.io   trace-func-0-00001   165m   3 OK / 3     True    
trace-func-1   http://trace-func-1.default.192.168.1.240.sslip.io   trace-func-1-00001   165m   3 OK / 3     True    
trace-func-2   http://trace-func-2.default.192.168.1.240.sslip.io   trace-func-2-00001   165m   3 OK / 3     True    
trace-func-3   http://trace-func-3.default.192.168.1.240.sslip.io   trace-func-3-00001   165m   3 OK / 3     True    
trace-func-4   http://trace-func-4.default.192.168.1.240.sslip.io   trace-func-4-00001   165m   3 OK / 3     True    
trace-func-5   http://trace-func-5.default.192.168.1.240.sslip.io   trace-func-5-00001   165m   3 OK / 3     True    
trace-func-6   http://trace-func-6.default.192.168.1.240.sslip.io   trace-func-6-00001   165m   3 OK / 3     True    
trace-func-7   http://trace-func-7.default.192.168.1.240.sslip.io   trace-func-7-00001   164m   1 OK / 3     False   RevisionFailed : Revision "trace-func-7-00001" failed with message: 0/2 nodes are available: 1 Too many pods, 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate..
trace-func-8   http://trace-func-8.default.192.168.1.240.sslip.io   trace-func-8-00001   164m   3 OK / 3     True    
trace-func-9   http://trace-func-9.default.192.168.1.240.sslip.io   trace-func-9-00001   164m   3 OK / 3     True

$ kubectl get pods
NAME                                            READY   STATUS                 RESTARTS   AGE
trace-func-7-00001-deployment-777876fd9-5czzg   0/2     CreateContainerError   559        158m
trace-func-7-00001-deployment-777876fd9-ftxp8   0/2     CreateContainerError   552        158m

$ kubectl describe pod trace-func-7-00001-deployment-777876fd9-5czzg
Name:         trace-func-7-00001-deployment-777876fd9-5czzg
Namespace:    default
Priority:     0
Node:         node-1.does-not-die.faas-sched-pg0.cloudlab.umass.edu/198.22.255.70
Start Time:   Sat, 11 Dec 2021 12:29:12 -0500
Labels:       app=trace-func-7-00001
              pod-template-hash=777876fd9
              service.istio.io/canonical-name=trace-func-7
              service.istio.io/canonical-revision=trace-func-7-00001
              serving.knative.dev/configuration=trace-func-7
              serving.knative.dev/configurationGeneration=1
              serving.knative.dev/configurationUID=86db8af2-a9f4-4d5d-ab28-93876fc86d01
              serving.knative.dev/revision=trace-func-7-00001
              serving.knative.dev/revisionUID=d0e78db0-ff8d-468a-a636-522b0c20d52a
              serving.knative.dev/service=trace-func-7
              serving.knative.dev/serviceUID=75d69aa7-d65b-458a-9a06-378a82ddfb83
Annotations:  autoscaling.knative.dev/target: 1
              cni.projectcalico.org/podIP: 192.168.1.245/32
              cni.projectcalico.org/podIPs: 192.168.1.245/32
              serving.knative.dev/creator: kubernetes-admin
Status:       Pending
IP:           192.168.1.245
IPs:
  IP:           192.168.1.245
Controlled By:  ReplicaSet/trace-func-7-00001-deployment-777876fd9
Containers:
  user-container:
    Container ID:   containerd://608d4edb0fef4da9ce54341c90398c9f6205119c6d9d28d4e5c983fef0742707
    Image:          index.docker.io/crccheck/hello-world@sha256:0404ca69b522f8629d7d4e9034a7afe0300b713354e8bf12ec9657581cf59400
    Image ID:       docker.io/crccheck/hello-world@sha256:0404ca69b522f8629d7d4e9034a7afe0300b713354e8bf12ec9657581cf59400
    Port:           50051/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       CreateContainerError
    Last State:     Terminated
      Exit Code:    0
      Started:      Mon, 01 Jan 0001 00:00:00 +0000
      Finished:     Mon, 01 Jan 0001 00:00:00 +0000
    Ready:          False
    Restart Count:  563
    Environment:
      GUEST_PORT:       50051
      GUEST_IMAGE:      amohoste/timed:latest
      MEM_SIZE_MB:      2048
      PORT:             50051
      K_REVISION:       trace-func-7-00001
      K_CONFIGURATION:  trace-func-7
      K_SERVICE:        trace-func-7
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m4ml9 (ro)
  queue-proxy:
    Container ID:   
    Image:          docker.io/vhiveease/queue-39be6f1d08a095bd076a71d288d295b6@sha256:2792802ac51ee222f01035c450b6718e3b40e810dec6b1d7f3ce7beefb5db2e0
    Image ID:       
    Ports:          8022/TCP, 9090/TCP, 9091/TCP, 8013/TCP
    Host Ports:     0/TCP, 0/TCP, 0/TCP, 0/TCP
    State:          Waiting
      Reason:       CreateContainerError
    Ready:          False
    Restart Count:  0
    Requests:
      cpu:      25m
    Readiness:  http-get http://:8013/ delay=0s timeout=1s period=1s #success=1 #failure=3
    Environment:
      SERVING_NAMESPACE:                 default
      SERVING_SERVICE:                   trace-func-7
      SERVING_CONFIGURATION:             trace-func-7
      SERVING_REVISION:                  trace-func-7-00001
      QUEUE_SERVING_PORT:                8013
      CONTAINER_CONCURRENCY:             1
      REVISION_TIMEOUT_SECONDS:          300
      SERVING_POD:                       trace-func-7-00001-deployment-777876fd9-5czzg (v1:metadata.name)
      SERVING_POD_IP:                     (v1:status.podIP)
      SERVING_LOGGING_CONFIG:            
      SERVING_LOGGING_LEVEL:             
      SERVING_REQUEST_LOG_TEMPLATE:      {"httpRequest": {"requestMethod": "{{.Request.Method}}", "requestUrl": "{{js .Request.RequestURI}}", "requestSize": "{{.Request.ContentLength}}", "status": {{.Response.Code}}, "responseSize": "{{.Response.Size}}", "userAgent": "{{js .Request.UserAgent}}", "remoteIp": "{{js .Request.RemoteAddr}}", "serverIp": "{{.Revision.PodIP}}", "referer": "{{js .Request.Referer}}", "latency": "{{.Response.Latency}}s", "protocol": "{{.Request.Proto}}"}, "traceId": "{{index .Request.Header "X-B3-Traceid"}}"}
      SERVING_ENABLE_REQUEST_LOG:        false
      SERVING_REQUEST_METRICS_BACKEND:   prometheus
      TRACING_CONFIG_BACKEND:            none
      TRACING_CONFIG_ZIPKIN_ENDPOINT:    
      TRACING_CONFIG_DEBUG:              false
      TRACING_CONFIG_SAMPLE_RATE:        0.1
      USER_PORT:                         50051
      SYSTEM_NAMESPACE:                  knative-serving
      METRICS_DOMAIN:                    knative.dev/internal/serving
      SERVING_READINESS_PROBE:           {"tcpSocket":{"port":50051,"host":"127.0.0.1"},"successThreshold":1}
      ENABLE_PROFILING:                  false
      SERVING_ENABLE_PROBE_REQUEST_LOG:  false
      METRICS_COLLECTOR_ADDRESS:         
      CONCURRENCY_STATE_ENDPOINT:        
      CONCURRENCY_STATE_TOKEN_PATH:      /var/run/secrets/tokens/state-token
      ENABLE_HTTP2_AUTO_DETECTION:       false
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m4ml9 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-m4ml9:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-m4ml9
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason  Age                  From     Message
  ----    ------  ----                 ----     -------
  Normal  Pulled  4s (x942 over 157m)  kubelet  Container image "index.docker.io/crccheck/hello-world@sha256:0404ca69b522f8629d7d4e9034a7afe0300b713354e8bf12ec9657581cf59400" already present on machine
